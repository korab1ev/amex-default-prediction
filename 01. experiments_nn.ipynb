{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b73039bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run import_libs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25242305",
   "metadata": {},
   "source": [
    "### get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b26bac4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 151)\n",
      "(458913, 151)\n",
      "(458913, 151)\n",
      "(458913, 162)\n",
      "(458913, 616)\n"
     ]
    }
   ],
   "source": [
    "df_train = get_train_data(TRAIN_PATH='./data/train.parquet')\n",
    "num_features = pd.read_csv(\"num_feats_after_filtering.csv\")[\"0\"].to_list()\n",
    "\n",
    "df_train_agg = get_df_w_aggrs(df=df_train, feats=num_features)\n",
    "df_train_target = get_target(TARGET_PATH='./data/train_labels.csv')\n",
    "df_train = get_train_data_with_target_merged(df_train=df_train_agg, df_train_target=df_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08b35bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(924621, 151)\n",
      "(924621, 151)\n",
      "(924621, 151)\n",
      "(924621, 162)\n",
      "(924621, 616)\n"
     ]
    }
   ],
   "source": [
    "df_test = get_test_data(TEST_PATH='./data/test.parquet')\n",
    "df_test = get_df_w_aggrs(df=df_test, feats=num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392b5047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B_30_last',\n",
       " 'B_38_last',\n",
       " 'D_114_last',\n",
       " 'D_116_last',\n",
       " 'D_117_last',\n",
       " 'D_120_last',\n",
       " 'D_126_last',\n",
       " 'D_63_last',\n",
       " 'D_64_last',\n",
       " 'D_66_last',\n",
       " 'D_68_last']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = [f\"{f}_last\" for f in ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']]\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eff39c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_feats = []\n",
    "delinq_feats = []\n",
    "spend_feats = []\n",
    "balance_feats = []\n",
    "risk_feats = []\n",
    "\n",
    "for feat in list(df_train):\n",
    "    if feat in cat_features:\n",
    "        continue\n",
    "    \n",
    "    if feat[0] == 'P':\n",
    "        #print(feat)\n",
    "        payment_feats.append(feat)\n",
    "    elif feat[0] == 'D':\n",
    "        delinq_feats.append(feat)\n",
    "    elif feat[0] == 'S':\n",
    "        spend_feats.append(feat)\n",
    "    elif feat[0] == 'B':\n",
    "        balance_feats.append(feat)\n",
    "    elif feat[0] == 'R':\n",
    "        risk_feats.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc0986ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(payment_feats) + len(delinq_feats) + len(spend_feats) + len(balance_feats) + len(risk_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "767e6122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = payment_feats + delinq_feats + spend_feats + balance_feats + risk_feats\n",
    "len(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e1ae7",
   "metadata": {},
   "source": [
    "### load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb2aba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    DEBUG = False\n",
    "    model = 'tabnet'\n",
    "    N_folds = 5\n",
    "    seed = 42\n",
    "    batch_size = 512\n",
    "    max_epochs = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa4a6ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(seed = CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89ea73cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory().percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbcdc958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using amex metric to evaluate tabnet\n",
    "class Amex_tabnet(Metric):\n",
    "    \n",
    "  def __init__(self):\n",
    "    self._name = 'amex_tabnet'\n",
    "    self._maximize = True\n",
    "\n",
    "  def __call__(self, y_true, y_pred):\n",
    "    amex = get_amex_metric_calculated(y_true, y_pred[:, 1])\n",
    "    return max(amex, 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c9c04d",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09cb5890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  --------------------------------------------------\n",
      "\n",
      "Training:  tabnet\n",
      "\n",
      "  --------------------------------------------------\n",
      "\n",
      "Seed:  42\n",
      "N folds:  5\n",
      "\n",
      "N features:  604\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n ', '-'*50)\n",
    "print('\\nTraining: ', CFG.model)\n",
    "print('\\n ', '-'*50)\n",
    "\n",
    "print('\\nSeed: ', CFG.seed)\n",
    "print('N folds: ', CFG.N_folds)\n",
    "\n",
    "print('\\nN features: ', len(num_features))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19a53462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (458913, 617) (924621, 616)\n"
     ]
    }
   ],
   "source": [
    "df_train.fillna(0, inplace=True)\n",
    "df_test.fillna(0, inplace=True)\n",
    "\n",
    "print('Shapes:', df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99ed279d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49261e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924621, 616)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0a46bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367130, 604)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4df9ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91783, 604)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_va.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08fa7e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91783"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_va.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cfefb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_va.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5272504f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91783, 604)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_va.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77b9ec71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924621, 616)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ab7972f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924621, 604)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[num_features].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774c3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "004f72a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924621,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d65bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b15ade0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db617b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "617"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "409f3184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train[num_features].columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c93a427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oobur\\Projects\\spbu_master\\sem4\\vkr\\.venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.51859 | val_0_auc: 0.91092 | val_0_accuracy: 0.83555 | val_0_amex_tabnet: 0.5967  |  0:00:59s\n",
      "epoch 1  | loss: 0.35551 | val_0_auc: 0.9277  | val_0_accuracy: 0.86246 | val_0_amex_tabnet: 0.6642  |  0:01:58s\n",
      "epoch 2  | loss: 0.31299 | val_0_auc: 0.93591 | val_0_accuracy: 0.87087 | val_0_amex_tabnet: 0.68442 |  0:02:58s\n",
      "epoch 3  | loss: 0.29255 | val_0_auc: 0.93984 | val_0_accuracy: 0.87697 | val_0_amex_tabnet: 0.7011  |  0:03:59s\n",
      "epoch 4  | loss: 0.28269 | val_0_auc: 0.9412  | val_0_accuracy: 0.87815 | val_0_amex_tabnet: 0.70547 |  0:04:59s\n",
      "epoch 5  | loss: 0.27169 | val_0_auc: 0.94764 | val_0_accuracy: 0.88494 | val_0_amex_tabnet: 0.73266 |  0:05:59s\n",
      "epoch 6  | loss: 0.25838 | val_0_auc: 0.95045 | val_0_accuracy: 0.88843 | val_0_amex_tabnet: 0.7434  |  0:07:00s\n",
      "epoch 7  | loss: 0.25037 | val_0_auc: 0.95238 | val_0_accuracy: 0.89001 | val_0_amex_tabnet: 0.75335 |  0:08:01s\n",
      "epoch 8  | loss: 0.24568 | val_0_auc: 0.95314 | val_0_accuracy: 0.89127 | val_0_amex_tabnet: 0.75683 |  0:09:02s\n",
      "epoch 9  | loss: 0.24329 | val_0_auc: 0.95397 | val_0_accuracy: 0.89262 | val_0_amex_tabnet: 0.76042 |  0:10:03s\n",
      "epoch 10 | loss: 0.24319 | val_0_auc: 0.95555 | val_0_accuracy: 0.89583 | val_0_amex_tabnet: 0.7683  |  0:11:05s\n",
      "epoch 11 | loss: 0.23688 | val_0_auc: 0.95738 | val_0_accuracy: 0.89727 | val_0_amex_tabnet: 0.77417 |  0:12:09s\n",
      "epoch 12 | loss: 0.23358 | val_0_auc: 0.95809 | val_0_accuracy: 0.89871 | val_0_amex_tabnet: 0.77662 |  0:13:13s\n",
      "epoch 13 | loss: 0.23115 | val_0_auc: 0.9586  | val_0_accuracy: 0.90053 | val_0_amex_tabnet: 0.77859 |  0:14:18s\n",
      "epoch 14 | loss: 0.22755 | val_0_auc: 0.95936 | val_0_accuracy: 0.9008  | val_0_amex_tabnet: 0.77996 |  0:15:24s\n",
      "epoch 15 | loss: 0.23307 | val_0_auc: 0.9584  | val_0_accuracy: 0.89956 | val_0_amex_tabnet: 0.77751 |  0:16:32s\n",
      "epoch 16 | loss: 0.2313  | val_0_auc: 0.95858 | val_0_accuracy: 0.89799 | val_0_amex_tabnet: 0.77758 |  0:17:50s\n",
      "epoch 17 | loss: 0.22933 | val_0_auc: 0.95919 | val_0_accuracy: 0.90093 | val_0_amex_tabnet: 0.78201 |  0:19:15s\n",
      "epoch 18 | loss: 0.22727 | val_0_auc: 0.95953 | val_0_accuracy: 0.90119 | val_0_amex_tabnet: 0.78224 |  0:20:43s\n",
      "epoch 19 | loss: 0.22533 | val_0_auc: 0.95984 | val_0_accuracy: 0.90152 | val_0_amex_tabnet: 0.78259 |  0:22:18s\n",
      "epoch 20 | loss: 0.22932 | val_0_auc: 0.95915 | val_0_accuracy: 0.90043 | val_0_amex_tabnet: 0.78161 |  0:23:59s\n",
      "epoch 21 | loss: 0.22813 | val_0_auc: 0.9586  | val_0_accuracy: 0.89908 | val_0_amex_tabnet: 0.77751 |  0:25:56s\n",
      "epoch 22 | loss: 0.22709 | val_0_auc: 0.95964 | val_0_accuracy: 0.9008  | val_0_amex_tabnet: 0.78127 |  0:28:18s\n",
      "epoch 23 | loss: 0.22513 | val_0_auc: 0.95981 | val_0_accuracy: 0.90118 | val_0_amex_tabnet: 0.7811  |  0:30:52s\n",
      "epoch 24 | loss: 0.22341 | val_0_auc: 0.96017 | val_0_accuracy: 0.90131 | val_0_amex_tabnet: 0.78403 |  0:33:34s\n",
      "epoch 25 | loss: 0.22731 | val_0_auc: 0.95915 | val_0_accuracy: 0.89874 | val_0_amex_tabnet: 0.77794 |  0:36:11s\n",
      "epoch 26 | loss: 0.22663 | val_0_auc: 0.95933 | val_0_accuracy: 0.90045 | val_0_amex_tabnet: 0.78192 |  0:39:00s\n",
      "epoch 27 | loss: 0.22547 | val_0_auc: 0.95927 | val_0_accuracy: 0.89956 | val_0_amex_tabnet: 0.78151 |  0:41:48s\n",
      "epoch 28 | loss: 0.22384 | val_0_auc: 0.9599  | val_0_accuracy: 0.90118 | val_0_amex_tabnet: 0.78307 |  0:44:39s\n",
      "epoch 29 | loss: 0.22191 | val_0_auc: 0.96023 | val_0_accuracy: 0.90207 | val_0_amex_tabnet: 0.78583 |  0:47:33s\n",
      "epoch 30 | loss: 0.22662 | val_0_auc: 0.95968 | val_0_accuracy: 0.90094 | val_0_amex_tabnet: 0.78378 |  0:50:16s\n",
      "epoch 31 | loss: 0.22573 | val_0_auc: 0.95978 | val_0_accuracy: 0.90113 | val_0_amex_tabnet: 0.78308 |  0:52:57s\n",
      "epoch 32 | loss: 0.22503 | val_0_auc: 0.95988 | val_0_accuracy: 0.90091 | val_0_amex_tabnet: 0.78265 |  0:55:42s\n",
      "epoch 33 | loss: 0.22316 | val_0_auc: 0.96024 | val_0_accuracy: 0.90189 | val_0_amex_tabnet: 0.7844  |  0:58:35s\n",
      "epoch 34 | loss: 0.22104 | val_0_auc: 0.96013 | val_0_accuracy: 0.90168 | val_0_amex_tabnet: 0.78476 |  1:01:33s\n",
      "epoch 35 | loss: 0.22601 | val_0_auc: 0.95978 | val_0_accuracy: 0.89903 | val_0_amex_tabnet: 0.78242 |  1:04:05s\n",
      "epoch 36 | loss: 0.22536 | val_0_auc: 0.95949 | val_0_accuracy: 0.90122 | val_0_amex_tabnet: 0.78178 |  1:06:42s\n",
      "epoch 37 | loss: 0.22415 | val_0_auc: 0.95993 | val_0_accuracy: 0.90154 | val_0_amex_tabnet: 0.7826  |  1:09:21s\n",
      "epoch 38 | loss: 0.22252 | val_0_auc: 0.96011 | val_0_accuracy: 0.90133 | val_0_amex_tabnet: 0.78431 |  1:12:14s\n",
      "epoch 39 | loss: 0.22057 | val_0_auc: 0.9601  | val_0_accuracy: 0.90156 | val_0_amex_tabnet: 0.78416 |  1:15:11s\n",
      "epoch 40 | loss: 0.22547 | val_0_auc: 0.95947 | val_0_accuracy: 0.89729 | val_0_amex_tabnet: 0.78264 |  1:16:59s\n",
      "epoch 41 | loss: 0.225   | val_0_auc: 0.95963 | val_0_accuracy: 0.9007  | val_0_amex_tabnet: 0.78129 |  1:18:51s\n",
      "epoch 42 | loss: 0.22353 | val_0_auc: 0.96001 | val_0_accuracy: 0.90152 | val_0_amex_tabnet: 0.78289 |  1:21:09s\n",
      "epoch 43 | loss: 0.22212 | val_0_auc: 0.96009 | val_0_accuracy: 0.90204 | val_0_amex_tabnet: 0.78404 |  1:23:57s\n",
      "epoch 44 | loss: 0.22042 | val_0_auc: 0.95996 | val_0_accuracy: 0.90107 | val_0_amex_tabnet: 0.7837  |  1:26:52s\n",
      "epoch 45 | loss: 0.22531 | val_0_auc: 0.95955 | val_0_accuracy: 0.89862 | val_0_amex_tabnet: 0.78082 |  1:28:26s\n",
      "epoch 46 | loss: 0.22445 | val_0_auc: 0.95967 | val_0_accuracy: 0.90135 | val_0_amex_tabnet: 0.7827  |  1:30:11s\n",
      "epoch 47 | loss: 0.22361 | val_0_auc: 0.96002 | val_0_accuracy: 0.90101 | val_0_amex_tabnet: 0.7834  |  1:32:32s\n",
      "epoch 48 | loss: 0.22171 | val_0_auc: 0.96006 | val_0_accuracy: 0.90135 | val_0_amex_tabnet: 0.78385 |  1:35:11s\n",
      "epoch 49 | loss: 0.21974 | val_0_auc: 0.96008 | val_0_accuracy: 0.90149 | val_0_amex_tabnet: 0.78338 |  1:37:58s\n",
      "epoch 50 | loss: 0.22511 | val_0_auc: 0.95948 | val_0_accuracy: 0.90007 | val_0_amex_tabnet: 0.78185 |  1:39:39s\n",
      "epoch 51 | loss: 0.22414 | val_0_auc: 0.95978 | val_0_accuracy: 0.9004  | val_0_amex_tabnet: 0.78325 |  1:41:42s\n",
      "epoch 52 | loss: 0.22364 | val_0_auc: 0.9598  | val_0_accuracy: 0.90158 | val_0_amex_tabnet: 0.78455 |  1:44:14s\n",
      "epoch 53 | loss: 0.22145 | val_0_auc: 0.96004 | val_0_accuracy: 0.90183 | val_0_amex_tabnet: 0.78431 |  1:46:53s\n",
      "epoch 54 | loss: 0.21962 | val_0_auc: 0.96014 | val_0_accuracy: 0.90176 | val_0_amex_tabnet: 0.78508 |  1:49:41s\n",
      "epoch 55 | loss: 0.2246  | val_0_auc: 0.95981 | val_0_accuracy: 0.90137 | val_0_amex_tabnet: 0.78224 |  1:51:19s\n",
      "epoch 56 | loss: 0.2243  | val_0_auc: 0.95975 | val_0_accuracy: 0.90139 | val_0_amex_tabnet: 0.78296 |  1:53:11s\n",
      "epoch 57 | loss: 0.22277 | val_0_auc: 0.95979 | val_0_accuracy: 0.89953 | val_0_amex_tabnet: 0.784   |  1:55:38s\n",
      "epoch 58 | loss: 0.22135 | val_0_auc: 0.95993 | val_0_accuracy: 0.90196 | val_0_amex_tabnet: 0.78447 |  1:58:23s\n",
      "epoch 59 | loss: 0.21948 | val_0_auc: 0.96015 | val_0_accuracy: 0.90171 | val_0_amex_tabnet: 0.78547 |  2:01:15s\n",
      "Stop training because you reached max_epochs = 60 with best_epoch = 29 and best_val_0_amex_tabnet = 0.78583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oobur\\Projects\\spbu_master\\sem4\\vkr\\.venv\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5 | 136.43 min\n",
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oobur\\Projects\\spbu_master\\sem4\\vkr\\.venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.51468 | val_0_auc: 0.91434 | val_0_accuracy: 0.83986 | val_0_amex_tabnet: 0.61337 |  0:00:58s\n",
      "epoch 1  | loss: 0.35197 | val_0_auc: 0.93174 | val_0_accuracy: 0.86868 | val_0_amex_tabnet: 0.67345 |  0:01:55s\n",
      "epoch 2  | loss: 0.30433 | val_0_auc: 0.93849 | val_0_accuracy: 0.87566 | val_0_amex_tabnet: 0.69687 |  0:02:54s\n",
      "epoch 3  | loss: 0.28564 | val_0_auc: 0.94177 | val_0_accuracy: 0.87843 | val_0_amex_tabnet: 0.7107  |  0:03:54s\n",
      "epoch 4  | loss: 0.27844 | val_0_auc: 0.94289 | val_0_accuracy: 0.88072 | val_0_amex_tabnet: 0.71519 |  0:04:54s\n",
      "epoch 5  | loss: 0.27055 | val_0_auc: 0.94771 | val_0_accuracy: 0.88674 | val_0_amex_tabnet: 0.73279 |  0:05:54s\n",
      "epoch 6  | loss: 0.25776 | val_0_auc: 0.95076 | val_0_accuracy: 0.89094 | val_0_amex_tabnet: 0.74791 |  0:06:54s\n",
      "epoch 7  | loss: 0.24945 | val_0_auc: 0.95318 | val_0_accuracy: 0.8925  | val_0_amex_tabnet: 0.75781 |  0:07:53s\n",
      "epoch 8  | loss: 0.24422 | val_0_auc: 0.95484 | val_0_accuracy: 0.89596 | val_0_amex_tabnet: 0.76509 |  0:08:54s\n",
      "epoch 9  | loss: 0.24072 | val_0_auc: 0.95572 | val_0_accuracy: 0.89662 | val_0_amex_tabnet: 0.76849 |  0:09:55s\n",
      "epoch 10 | loss: 0.24004 | val_0_auc: 0.95716 | val_0_accuracy: 0.89848 | val_0_amex_tabnet: 0.77599 |  0:10:55s\n",
      "epoch 11 | loss: 0.23562 | val_0_auc: 0.95781 | val_0_accuracy: 0.89932 | val_0_amex_tabnet: 0.77645 |  0:11:58s\n",
      "epoch 12 | loss: 0.23377 | val_0_auc: 0.95851 | val_0_accuracy: 0.899   | val_0_amex_tabnet: 0.77827 |  0:13:02s\n",
      "epoch 13 | loss: 0.23127 | val_0_auc: 0.95916 | val_0_accuracy: 0.90108 | val_0_amex_tabnet: 0.78422 |  0:14:06s\n",
      "epoch 14 | loss: 0.22802 | val_0_auc: 0.95981 | val_0_accuracy: 0.90142 | val_0_amex_tabnet: 0.78539 |  0:15:11s\n",
      "epoch 15 | loss: 0.23286 | val_0_auc: 0.95899 | val_0_accuracy: 0.89983 | val_0_amex_tabnet: 0.78229 |  0:16:19s\n",
      "epoch 16 | loss: 0.23161 | val_0_auc: 0.95935 | val_0_accuracy: 0.9012  | val_0_amex_tabnet: 0.78223 |  0:17:34s\n",
      "epoch 17 | loss: 0.23043 | val_0_auc: 0.95961 | val_0_accuracy: 0.90232 | val_0_amex_tabnet: 0.78446 |  0:18:58s\n",
      "epoch 18 | loss: 0.22817 | val_0_auc: 0.95986 | val_0_accuracy: 0.90191 | val_0_amex_tabnet: 0.78471 |  0:20:26s\n",
      "epoch 19 | loss: 0.22644 | val_0_auc: 0.96029 | val_0_accuracy: 0.90217 | val_0_amex_tabnet: 0.78738 |  0:21:58s\n",
      "epoch 20 | loss: 0.23013 | val_0_auc: 0.95969 | val_0_accuracy: 0.90083 | val_0_amex_tabnet: 0.78437 |  0:23:40s\n",
      "epoch 21 | loss: 0.22946 | val_0_auc: 0.96014 | val_0_accuracy: 0.90105 | val_0_amex_tabnet: 0.78588 |  0:25:38s\n",
      "epoch 22 | loss: 0.22842 | val_0_auc: 0.95979 | val_0_accuracy: 0.90155 | val_0_amex_tabnet: 0.78575 |  0:27:57s\n",
      "epoch 23 | loss: 0.22707 | val_0_auc: 0.96014 | val_0_accuracy: 0.90192 | val_0_amex_tabnet: 0.78618 |  0:30:33s\n",
      "epoch 24 | loss: 0.22506 | val_0_auc: 0.96057 | val_0_accuracy: 0.90309 | val_0_amex_tabnet: 0.7885  |  0:33:19s\n",
      "epoch 25 | loss: 0.22875 | val_0_auc: 0.95951 | val_0_accuracy: 0.90108 | val_0_amex_tabnet: 0.78302 |  0:36:08s\n",
      "epoch 26 | loss: 0.22801 | val_0_auc: 0.96032 | val_0_accuracy: 0.90262 | val_0_amex_tabnet: 0.78754 |  0:38:56s\n",
      "epoch 27 | loss: 0.22693 | val_0_auc: 0.96056 | val_0_accuracy: 0.90237 | val_0_amex_tabnet: 0.78547 |  0:41:46s\n",
      "epoch 28 | loss: 0.22532 | val_0_auc: 0.9607  | val_0_accuracy: 0.90328 | val_0_amex_tabnet: 0.7883  |  0:44:41s\n",
      "epoch 29 | loss: 0.22341 | val_0_auc: 0.96095 | val_0_accuracy: 0.90386 | val_0_amex_tabnet: 0.79004 |  0:47:40s\n",
      "epoch 30 | loss: 0.22793 | val_0_auc: 0.95979 | val_0_accuracy: 0.9014  | val_0_amex_tabnet: 0.78411 |  0:50:28s\n",
      "epoch 31 | loss: 0.22688 | val_0_auc: 0.96049 | val_0_accuracy: 0.9034  | val_0_amex_tabnet: 0.78589 |  0:53:12s\n",
      "epoch 32 | loss: 0.22602 | val_0_auc: 0.96044 | val_0_accuracy: 0.90246 | val_0_amex_tabnet: 0.78592 |  0:55:57s\n",
      "epoch 33 | loss: 0.22438 | val_0_auc: 0.96077 | val_0_accuracy: 0.90394 | val_0_amex_tabnet: 0.78933 |  0:58:51s\n",
      "epoch 34 | loss: 0.22251 | val_0_auc: 0.96094 | val_0_accuracy: 0.90366 | val_0_amex_tabnet: 0.78863 |  1:01:51s\n",
      "epoch 35 | loss: 0.22687 | val_0_auc: 0.95998 | val_0_accuracy: 0.90266 | val_0_amex_tabnet: 0.786   |  1:04:15s\n",
      "epoch 36 | loss: 0.22618 | val_0_auc: 0.96031 | val_0_accuracy: 0.90286 | val_0_amex_tabnet: 0.78685 |  1:06:41s\n",
      "epoch 37 | loss: 0.22521 | val_0_auc: 0.96058 | val_0_accuracy: 0.90291 | val_0_amex_tabnet: 0.78759 |  1:09:16s\n",
      "epoch 38 | loss: 0.22406 | val_0_auc: 0.96059 | val_0_accuracy: 0.90301 | val_0_amex_tabnet: 0.78728 |  1:12:02s\n",
      "epoch 39 | loss: 0.22184 | val_0_auc: 0.96081 | val_0_accuracy: 0.90385 | val_0_amex_tabnet: 0.78975 |  1:14:56s\n",
      "epoch 40 | loss: 0.2264  | val_0_auc: 0.96018 | val_0_accuracy: 0.90294 | val_0_amex_tabnet: 0.78569 |  1:16:40s\n",
      "epoch 41 | loss: 0.22612 | val_0_auc: 0.96045 | val_0_accuracy: 0.90256 | val_0_amex_tabnet: 0.78717 |  1:18:21s\n",
      "epoch 42 | loss: 0.22483 | val_0_auc: 0.96033 | val_0_accuracy: 0.90134 | val_0_amex_tabnet: 0.78713 |  1:20:32s\n",
      "epoch 43 | loss: 0.22346 | val_0_auc: 0.96049 | val_0_accuracy: 0.90238 | val_0_amex_tabnet: 0.78662 |  1:23:13s\n",
      "epoch 44 | loss: 0.22174 | val_0_auc: 0.96082 | val_0_accuracy: 0.90425 | val_0_amex_tabnet: 0.78921 |  1:26:07s\n",
      "epoch 45 | loss: 0.22627 | val_0_auc: 0.96008 | val_0_accuracy: 0.90292 | val_0_amex_tabnet: 0.78563 |  1:27:45s\n",
      "epoch 46 | loss: 0.22558 | val_0_auc: 0.96037 | val_0_accuracy: 0.90124 | val_0_amex_tabnet: 0.78806 |  1:29:38s\n",
      "epoch 47 | loss: 0.22445 | val_0_auc: 0.96051 | val_0_accuracy: 0.90293 | val_0_amex_tabnet: 0.78714 |  1:32:06s\n",
      "epoch 48 | loss: 0.22306 | val_0_auc: 0.96064 | val_0_accuracy: 0.90337 | val_0_amex_tabnet: 0.78811 |  1:34:51s\n",
      "epoch 49 | loss: 0.22147 | val_0_auc: 0.96074 | val_0_accuracy: 0.90347 | val_0_amex_tabnet: 0.78785 |  1:37:42s\n",
      "epoch 50 | loss: 0.2255  | val_0_auc: 0.96021 | val_0_accuracy: 0.90256 | val_0_amex_tabnet: 0.7879  |  1:39:26s\n",
      "epoch 51 | loss: 0.22516 | val_0_auc: 0.9604  | val_0_accuracy: 0.90263 | val_0_amex_tabnet: 0.78601 |  1:41:20s\n",
      "epoch 52 | loss: 0.22385 | val_0_auc: 0.96055 | val_0_accuracy: 0.90218 | val_0_amex_tabnet: 0.78697 |  1:43:47s\n",
      "epoch 53 | loss: 0.22251 | val_0_auc: 0.96049 | val_0_accuracy: 0.90272 | val_0_amex_tabnet: 0.7878  |  1:46:32s\n",
      "epoch 54 | loss: 0.22109 | val_0_auc: 0.96089 | val_0_accuracy: 0.90283 | val_0_amex_tabnet: 0.7878  |  1:49:23s\n",
      "epoch 55 | loss: 0.22576 | val_0_auc: 0.96027 | val_0_accuracy: 0.90115 | val_0_amex_tabnet: 0.78639 |  1:51:00s\n",
      "epoch 56 | loss: 0.22485 | val_0_auc: 0.96024 | val_0_accuracy: 0.90256 | val_0_amex_tabnet: 0.78746 |  1:52:47s\n",
      "epoch 57 | loss: 0.2238  | val_0_auc: 0.96034 | val_0_accuracy: 0.9028  | val_0_amex_tabnet: 0.78646 |  1:55:17s\n",
      "epoch 58 | loss: 0.22209 | val_0_auc: 0.96068 | val_0_accuracy: 0.90238 | val_0_amex_tabnet: 0.78731 |  1:57:58s\n",
      "epoch 59 | loss: 0.22059 | val_0_auc: 0.9609  | val_0_accuracy: 0.90311 | val_0_amex_tabnet: 0.78859 |  2:00:50s\n",
      "Stop training because you reached max_epochs = 60 with best_epoch = 29 and best_val_0_amex_tabnet = 0.79004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oobur\\Projects\\spbu_master\\sem4\\vkr\\.venv\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2/5 | 137.02 min\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oobur\\Projects\\spbu_master\\sem4\\vkr\\.venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.52439 | val_0_auc: 0.90668 | val_0_accuracy: 0.83744 | val_0_amex_tabnet: 0.59568 |  0:00:59s\n",
      "epoch 1  | loss: 0.37264 | val_0_auc: 0.92558 | val_0_accuracy: 0.85822 | val_0_amex_tabnet: 0.64914 |  0:01:58s\n",
      "epoch 2  | loss: 0.32428 | val_0_auc: 0.93421 | val_0_accuracy: 0.86786 | val_0_amex_tabnet: 0.68245 |  0:02:58s\n",
      "epoch 3  | loss: 0.29638 | val_0_auc: 0.93786 | val_0_accuracy: 0.87405 | val_0_amex_tabnet: 0.69538 |  0:03:59s\n",
      "epoch 4  | loss: 0.2869  | val_0_auc: 0.93995 | val_0_accuracy: 0.87652 | val_0_amex_tabnet: 0.70357 |  0:04:59s\n",
      "epoch 5  | loss: 0.27785 | val_0_auc: 0.94383 | val_0_accuracy: 0.88035 | val_0_amex_tabnet: 0.72507 |  0:05:59s\n",
      "epoch 6  | loss: 0.26409 | val_0_auc: 0.94931 | val_0_accuracy: 0.88776 | val_0_amex_tabnet: 0.74506 |  0:06:59s\n",
      "epoch 7  | loss: 0.25578 | val_0_auc: 0.95198 | val_0_accuracy: 0.89083 | val_0_amex_tabnet: 0.75392 |  0:08:00s\n",
      "epoch 8  | loss: 0.24912 | val_0_auc: 0.95349 | val_0_accuracy: 0.89281 | val_0_amex_tabnet: 0.75973 |  0:09:01s\n",
      "epoch 9  | loss: 0.24456 | val_0_auc: 0.95437 | val_0_accuracy: 0.89336 | val_0_amex_tabnet: 0.76392 |  0:10:03s\n",
      "epoch 10 | loss: 0.24261 | val_0_auc: 0.95667 | val_0_accuracy: 0.89556 | val_0_amex_tabnet: 0.77094 |  0:11:04s\n",
      "epoch 11 | loss: 0.23713 | val_0_auc: 0.95752 | val_0_accuracy: 0.89822 | val_0_amex_tabnet: 0.77634 |  0:12:07s\n",
      "epoch 12 | loss: 0.23423 | val_0_auc: 0.9585  | val_0_accuracy: 0.89896 | val_0_amex_tabnet: 0.78063 |  0:13:11s\n",
      "epoch 13 | loss: 0.23121 | val_0_auc: 0.95915 | val_0_accuracy: 0.90078 | val_0_amex_tabnet: 0.78288 |  0:14:16s\n",
      "epoch 14 | loss: 0.22822 | val_0_auc: 0.95953 | val_0_accuracy: 0.90123 | val_0_amex_tabnet: 0.78558 |  0:15:22s\n",
      "epoch 15 | loss: 0.23306 | val_0_auc: 0.95848 | val_0_accuracy: 0.89909 | val_0_amex_tabnet: 0.77896 |  0:16:29s\n",
      "epoch 16 | loss: 0.23182 | val_0_auc: 0.95933 | val_0_accuracy: 0.90151 | val_0_amex_tabnet: 0.78522 |  0:17:47s\n",
      "epoch 17 | loss: 0.22988 | val_0_auc: 0.95936 | val_0_accuracy: 0.9011  | val_0_amex_tabnet: 0.78451 |  0:19:13s\n",
      "epoch 18 | loss: 0.22816 | val_0_auc: 0.95988 | val_0_accuracy: 0.90132 | val_0_amex_tabnet: 0.78457 |  0:20:42s\n",
      "epoch 19 | loss: 0.2258  | val_0_auc: 0.96022 | val_0_accuracy: 0.90257 | val_0_amex_tabnet: 0.78756 |  0:22:16s\n",
      "epoch 20 | loss: 0.22974 | val_0_auc: 0.95935 | val_0_accuracy: 0.90028 | val_0_amex_tabnet: 0.78413 |  0:23:58s\n",
      "epoch 21 | loss: 0.22923 | val_0_auc: 0.95897 | val_0_accuracy: 0.90014 | val_0_amex_tabnet: 0.7824  |  0:25:51s\n",
      "epoch 22 | loss: 0.2276  | val_0_auc: 0.95971 | val_0_accuracy: 0.90178 | val_0_amex_tabnet: 0.78501 |  0:28:05s\n",
      "epoch 23 | loss: 0.22599 | val_0_auc: 0.96028 | val_0_accuracy: 0.90288 | val_0_amex_tabnet: 0.78833 |  0:30:32s\n",
      "epoch 24 | loss: 0.22416 | val_0_auc: 0.96029 | val_0_accuracy: 0.90182 | val_0_amex_tabnet: 0.78669 |  0:33:02s\n",
      "epoch 25 | loss: 0.22777 | val_0_auc: 0.95989 | val_0_accuracy: 0.90224 | val_0_amex_tabnet: 0.78626 |  0:35:36s\n",
      "epoch 26 | loss: 0.22737 | val_0_auc: 0.96009 | val_0_accuracy: 0.90187 | val_0_amex_tabnet: 0.78805 |  0:38:19s\n",
      "epoch 27 | loss: 0.22612 | val_0_auc: 0.96022 | val_0_accuracy: 0.90219 | val_0_amex_tabnet: 0.78869 |  0:41:11s\n",
      "epoch 28 | loss: 0.22443 | val_0_auc: 0.96037 | val_0_accuracy: 0.90241 | val_0_amex_tabnet: 0.78797 |  0:44:06s\n",
      "epoch 29 | loss: 0.22266 | val_0_auc: 0.96076 | val_0_accuracy: 0.90329 | val_0_amex_tabnet: 0.7898  |  0:47:01s\n",
      "epoch 30 | loss: 0.22685 | val_0_auc: 0.96036 | val_0_accuracy: 0.90305 | val_0_amex_tabnet: 0.78908 |  0:49:35s\n",
      "epoch 31 | loss: 0.22702 | val_0_auc: 0.95986 | val_0_accuracy: 0.90169 | val_0_amex_tabnet: 0.78665 |  0:52:13s\n",
      "epoch 32 | loss: 0.22543 | val_0_auc: 0.96023 | val_0_accuracy: 0.90219 | val_0_amex_tabnet: 0.78735 |  0:54:57s\n",
      "epoch 33 | loss: 0.22366 | val_0_auc: 0.96053 | val_0_accuracy: 0.90259 | val_0_amex_tabnet: 0.78948 |  0:57:47s\n",
      "epoch 34 | loss: 0.22162 | val_0_auc: 0.96052 | val_0_accuracy: 0.90263 | val_0_amex_tabnet: 0.78926 |  1:00:41s\n",
      "epoch 35 | loss: 0.22639 | val_0_auc: 0.95997 | val_0_accuracy: 0.90126 | val_0_amex_tabnet: 0.7863  |  1:03:16s\n",
      "epoch 36 | loss: 0.22581 | val_0_auc: 0.96038 | val_0_accuracy: 0.90306 | val_0_amex_tabnet: 0.78904 |  1:05:54s\n",
      "epoch 37 | loss: 0.22466 | val_0_auc: 0.96042 | val_0_accuracy: 0.90238 | val_0_amex_tabnet: 0.78893 |  1:08:36s\n",
      "epoch 38 | loss: 0.22282 | val_0_auc: 0.96049 | val_0_accuracy: 0.90308 | val_0_amex_tabnet: 0.79009 |  1:11:29s\n",
      "epoch 39 | loss: 0.22109 | val_0_auc: 0.96063 | val_0_accuracy: 0.90271 | val_0_amex_tabnet: 0.78885 |  1:14:28s\n",
      "epoch 40 | loss: 0.22578 | val_0_auc: 0.95998 | val_0_accuracy: 0.90132 | val_0_amex_tabnet: 0.78631 |  1:16:18s\n",
      "epoch 41 | loss: 0.22553 | val_0_auc: 0.96045 | val_0_accuracy: 0.90251 | val_0_amex_tabnet: 0.79007 |  1:18:10s\n",
      "epoch 42 | loss: 0.22428 | val_0_auc: 0.96045 | val_0_accuracy: 0.90315 | val_0_amex_tabnet: 0.78747 |  1:20:32s\n",
      "epoch 43 | loss: 0.22286 | val_0_auc: 0.96039 | val_0_accuracy: 0.902   | val_0_amex_tabnet: 0.78884 |  1:23:17s\n",
      "epoch 44 | loss: 0.2207  | val_0_auc: 0.96045 | val_0_accuracy: 0.90217 | val_0_amex_tabnet: 0.7877  |  1:26:11s\n",
      "epoch 45 | loss: 0.22544 | val_0_auc: 0.95987 | val_0_accuracy: 0.90163 | val_0_amex_tabnet: 0.78626 |  1:27:50s\n",
      "epoch 46 | loss: 0.22509 | val_0_auc: 0.96009 | val_0_accuracy: 0.90227 | val_0_amex_tabnet: 0.78845 |  1:29:40s\n",
      "epoch 47 | loss: 0.22389 | val_0_auc: 0.96027 | val_0_accuracy: 0.90268 | val_0_amex_tabnet: 0.78736 |  1:32:06s\n",
      "epoch 48 | loss: 0.22228 | val_0_auc: 0.9603  | val_0_accuracy: 0.90262 | val_0_amex_tabnet: 0.78793 |  1:34:48s\n",
      "epoch 49 | loss: 0.22019 | val_0_auc: 0.96054 | val_0_accuracy: 0.90215 | val_0_amex_tabnet: 0.79027 |  1:37:42s\n",
      "epoch 50 | loss: 0.22541 | val_0_auc: 0.96004 | val_0_accuracy: 0.90277 | val_0_amex_tabnet: 0.7867  |  1:39:22s\n",
      "epoch 51 | loss: 0.22457 | val_0_auc: 0.96015 | val_0_accuracy: 0.90142 | val_0_amex_tabnet: 0.78868 |  1:41:21s\n",
      "epoch 52 | loss: 0.22387 | val_0_auc: 0.96044 | val_0_accuracy: 0.90276 | val_0_amex_tabnet: 0.78933 |  1:43:55s\n",
      "epoch 53 | loss: 0.22201 | val_0_auc: 0.96051 | val_0_accuracy: 0.90261 | val_0_amex_tabnet: 0.79028 |  1:46:40s\n",
      "epoch 54 | loss: 0.21997 | val_0_auc: 0.96069 | val_0_accuracy: 0.90208 | val_0_amex_tabnet: 0.7914  |  1:49:35s\n",
      "epoch 55 | loss: 0.22513 | val_0_auc: 0.95999 | val_0_accuracy: 0.90208 | val_0_amex_tabnet: 0.78621 |  1:51:15s\n",
      "epoch 56 | loss: 0.22438 | val_0_auc: 0.96009 | val_0_accuracy: 0.90188 | val_0_amex_tabnet: 0.78736 |  1:53:06s\n",
      "epoch 57 | loss: 0.22341 | val_0_auc: 0.96023 | val_0_accuracy: 0.90292 | val_0_amex_tabnet: 0.78818 |  1:55:39s\n",
      "epoch 58 | loss: 0.22194 | val_0_auc: 0.96031 | val_0_accuracy: 0.90179 | val_0_amex_tabnet: 0.7901  |  1:58:24s\n",
      "epoch 59 | loss: 0.21999 | val_0_auc: 0.96059 | val_0_accuracy: 0.90251 | val_0_amex_tabnet: 0.78996 |  2:01:15s\n",
      "Stop training because you reached max_epochs = 60 with best_epoch = 54 and best_val_0_amex_tabnet = 0.7914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oobur\\Projects\\spbu_master\\sem4\\vkr\\.venv\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3/5 | 136.81 min\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oobur\\Projects\\spbu_master\\sem4\\vkr\\.venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.52531 | val_0_auc: 0.90527 | val_0_accuracy: 0.82896 | val_0_amex_tabnet: 0.59258 |  0:00:59s\n",
      "epoch 1  | loss: 0.36712 | val_0_auc: 0.92433 | val_0_accuracy: 0.85669 | val_0_amex_tabnet: 0.64673 |  0:01:58s\n",
      "epoch 2  | loss: 0.32723 | val_0_auc: 0.93244 | val_0_accuracy: 0.86539 | val_0_amex_tabnet: 0.67148 |  0:02:58s\n",
      "epoch 3  | loss: 0.29798 | val_0_auc: 0.93962 | val_0_accuracy: 0.87579 | val_0_amex_tabnet: 0.70256 |  0:03:58s\n",
      "epoch 4  | loss: 0.28263 | val_0_auc: 0.94099 | val_0_accuracy: 0.878   | val_0_amex_tabnet: 0.70871 |  0:04:59s\n",
      "epoch 5  | loss: 0.27045 | val_0_auc: 0.94763 | val_0_accuracy: 0.88654 | val_0_amex_tabnet: 0.73839 |  0:06:00s\n",
      "epoch 6  | loss: 0.25632 | val_0_auc: 0.9505  | val_0_accuracy: 0.89026 | val_0_amex_tabnet: 0.74739 |  0:07:00s\n",
      "epoch 7  | loss: 0.24939 | val_0_auc: 0.95265 | val_0_accuracy: 0.89299 | val_0_amex_tabnet: 0.75847 |  0:08:01s\n",
      "epoch 8  | loss: 0.24489 | val_0_auc: 0.9535  | val_0_accuracy: 0.89391 | val_0_amex_tabnet: 0.76209 |  0:09:02s\n",
      "epoch 9  | loss: 0.24229 | val_0_auc: 0.95403 | val_0_accuracy: 0.89403 | val_0_amex_tabnet: 0.76438 |  0:10:04s\n",
      "epoch 10 | loss: 0.2418  | val_0_auc: 0.95574 | val_0_accuracy: 0.89533 | val_0_amex_tabnet: 0.77056 |  0:11:05s\n",
      "epoch 11 | loss: 0.2367  | val_0_auc: 0.95739 | val_0_accuracy: 0.89743 | val_0_amex_tabnet: 0.7756  |  0:12:09s\n",
      "epoch 12 | loss: 0.23387 | val_0_auc: 0.95814 | val_0_accuracy: 0.89852 | val_0_amex_tabnet: 0.77915 |  0:13:12s\n",
      "epoch 13 | loss: 0.23097 | val_0_auc: 0.95865 | val_0_accuracy: 0.899   | val_0_amex_tabnet: 0.78181 |  0:14:17s\n",
      "epoch 14 | loss: 0.2277  | val_0_auc: 0.95936 | val_0_accuracy: 0.89946 | val_0_amex_tabnet: 0.78465 |  0:15:22s\n",
      "epoch 15 | loss: 0.23289 | val_0_auc: 0.95825 | val_0_accuracy: 0.89641 | val_0_amex_tabnet: 0.77918 |  0:16:31s\n",
      "epoch 16 | loss: 0.23155 | val_0_auc: 0.95847 | val_0_accuracy: 0.89861 | val_0_amex_tabnet: 0.77929 |  0:17:52s\n",
      "epoch 17 | loss: 0.23002 | val_0_auc: 0.95912 | val_0_accuracy: 0.89982 | val_0_amex_tabnet: 0.78307 |  0:19:18s\n",
      "epoch 18 | loss: 0.228   | val_0_auc: 0.95909 | val_0_accuracy: 0.89986 | val_0_amex_tabnet: 0.78241 |  0:20:46s\n",
      "epoch 19 | loss: 0.22565 | val_0_auc: 0.9599  | val_0_accuracy: 0.90105 | val_0_amex_tabnet: 0.78479 |  0:22:16s\n",
      "epoch 20 | loss: 0.23022 | val_0_auc: 0.95899 | val_0_accuracy: 0.89892 | val_0_amex_tabnet: 0.7824  |  0:23:53s\n",
      "epoch 21 | loss: 0.22904 | val_0_auc: 0.95927 | val_0_accuracy: 0.89952 | val_0_amex_tabnet: 0.78283 |  0:25:46s\n",
      "epoch 22 | loss: 0.22807 | val_0_auc: 0.95969 | val_0_accuracy: 0.9007  | val_0_amex_tabnet: 0.78385 |  0:28:04s\n",
      "epoch 23 | loss: 0.2263  | val_0_auc: 0.95996 | val_0_accuracy: 0.89966 | val_0_amex_tabnet: 0.78636 |  0:30:35s\n",
      "epoch 24 | loss: 0.22456 | val_0_auc: 0.96023 | val_0_accuracy: 0.90076 | val_0_amex_tabnet: 0.78643 |  0:33:14s\n",
      "epoch 25 | loss: 0.22833 | val_0_auc: 0.95933 | val_0_accuracy: 0.89814 | val_0_amex_tabnet: 0.78361 |  0:36:02s\n",
      "epoch 26 | loss: 0.22802 | val_0_auc: 0.95933 | val_0_accuracy: 0.89985 | val_0_amex_tabnet: 0.78424 |  0:38:56s\n",
      "epoch 27 | loss: 0.22665 | val_0_auc: 0.96012 | val_0_accuracy: 0.90105 | val_0_amex_tabnet: 0.78614 |  0:41:52s\n",
      "epoch 28 | loss: 0.22521 | val_0_auc: 0.96015 | val_0_accuracy: 0.90104 | val_0_amex_tabnet: 0.78387 |  0:44:53s\n",
      "epoch 29 | loss: 0.22358 | val_0_auc: 0.96036 | val_0_accuracy: 0.90166 | val_0_amex_tabnet: 0.78754 |  0:47:56s\n",
      "epoch 30 | loss: 0.2277  | val_0_auc: 0.95926 | val_0_accuracy: 0.89863 | val_0_amex_tabnet: 0.78367 |  0:50:42s\n",
      "epoch 31 | loss: 0.22714 | val_0_auc: 0.95974 | val_0_accuracy: 0.90053 | val_0_amex_tabnet: 0.78545 |  0:53:29s\n",
      "epoch 32 | loss: 0.22609 | val_0_auc: 0.95986 | val_0_accuracy: 0.90109 | val_0_amex_tabnet: 0.78459 |  0:56:19s\n",
      "epoch 33 | loss: 0.22463 | val_0_auc: 0.96012 | val_0_accuracy: 0.90088 | val_0_amex_tabnet: 0.78704 |  0:59:17s\n",
      "epoch 34 | loss: 0.2228  | val_0_auc: 0.96032 | val_0_accuracy: 0.9014  | val_0_amex_tabnet: 0.78636 |  1:02:21s\n",
      "epoch 35 | loss: 0.2269  | val_0_auc: 0.95977 | val_0_accuracy: 0.90075 | val_0_amex_tabnet: 0.78408 |  1:04:49s\n",
      "epoch 36 | loss: 0.22649 | val_0_auc: 0.9597  | val_0_accuracy: 0.90025 | val_0_amex_tabnet: 0.78469 |  1:07:27s\n",
      "epoch 37 | loss: 0.2253  | val_0_auc: 0.96001 | val_0_accuracy: 0.8995  | val_0_amex_tabnet: 0.78559 |  1:10:07s\n",
      "epoch 38 | loss: 0.22412 | val_0_auc: 0.96013 | val_0_accuracy: 0.90104 | val_0_amex_tabnet: 0.78728 |  1:12:57s\n",
      "epoch 39 | loss: 0.22255 | val_0_auc: 0.96034 | val_0_accuracy: 0.90131 | val_0_amex_tabnet: 0.78869 |  1:15:56s\n",
      "epoch 40 | loss: 0.22712 | val_0_auc: 0.95958 | val_0_accuracy: 0.89999 | val_0_amex_tabnet: 0.78447 |  1:17:52s\n",
      "epoch 41 | loss: 0.22623 | val_0_auc: 0.95987 | val_0_accuracy: 0.90132 | val_0_amex_tabnet: 0.78483 |  1:19:50s\n",
      "epoch 42 | loss: 0.22507 | val_0_auc: 0.96007 | val_0_accuracy: 0.90087 | val_0_amex_tabnet: 0.78542 |  1:22:11s\n",
      "epoch 43 | loss: 0.22346 | val_0_auc: 0.96002 | val_0_accuracy: 0.9006  | val_0_amex_tabnet: 0.78664 |  1:25:02s\n",
      "epoch 44 | loss: 0.22187 | val_0_auc: 0.96026 | val_0_accuracy: 0.90119 | val_0_amex_tabnet: 0.78859 |  1:28:03s\n",
      "epoch 45 | loss: 0.22649 | val_0_auc: 0.9599  | val_0_accuracy: 0.90084 | val_0_amex_tabnet: 0.78575 |  1:29:43s\n",
      "epoch 46 | loss: 0.22613 | val_0_auc: 0.95972 | val_0_accuracy: 0.90019 | val_0_amex_tabnet: 0.78377 |  1:31:44s\n",
      "epoch 47 | loss: 0.22507 | val_0_auc: 0.96007 | val_0_accuracy: 0.90067 | val_0_amex_tabnet: 0.78704 |  1:34:14s\n",
      "epoch 48 | loss: 0.22356 | val_0_auc: 0.96021 | val_0_accuracy: 0.90154 | val_0_amex_tabnet: 0.78785 |  1:37:07s\n",
      "epoch 49 | loss: 0.2217  | val_0_auc: 0.96029 | val_0_accuracy: 0.90164 | val_0_amex_tabnet: 0.78691 |  1:40:07s\n",
      "epoch 50 | loss: 0.22591 | val_0_auc: 0.95962 | val_0_accuracy: 0.90076 | val_0_amex_tabnet: 0.78492 |  1:41:49s\n",
      "epoch 51 | loss: 0.22555 | val_0_auc: 0.95981 | val_0_accuracy: 0.90068 | val_0_amex_tabnet: 0.78416 |  1:43:44s\n",
      "epoch 52 | loss: 0.22466 | val_0_auc: 0.95998 | val_0_accuracy: 0.90072 | val_0_amex_tabnet: 0.78656 |  1:46:18s\n",
      "epoch 53 | loss: 0.22321 | val_0_auc: 0.96014 | val_0_accuracy: 0.90128 | val_0_amex_tabnet: 0.7863  |  1:49:04s\n",
      "epoch 54 | loss: 0.22128 | val_0_auc: 0.96011 | val_0_accuracy: 0.90116 | val_0_amex_tabnet: 0.78553 |  1:51:59s\n",
      "epoch 55 | loss: 0.22616 | val_0_auc: 0.95977 | val_0_accuracy: 0.89739 | val_0_amex_tabnet: 0.78366 |  1:53:42s\n",
      "epoch 56 | loss: 0.22505 | val_0_auc: 0.95974 | val_0_accuracy: 0.90018 | val_0_amex_tabnet: 0.78482 |  1:55:38s\n",
      "epoch 57 | loss: 0.22445 | val_0_auc: 0.9597  | val_0_accuracy: 0.90031 | val_0_amex_tabnet: 0.78421 |  1:58:16s\n",
      "epoch 58 | loss: 0.22256 | val_0_auc: 0.96028 | val_0_accuracy: 0.90177 | val_0_amex_tabnet: 0.78872 |  2:01:05s\n",
      "epoch 59 | loss: 0.22105 | val_0_auc: 0.96033 | val_0_accuracy: 0.90139 | val_0_amex_tabnet: 0.788   |  2:03:57s\n",
      "Stop training because you reached max_epochs = 60 with best_epoch = 58 and best_val_0_amex_tabnet = 0.78872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oobur\\Projects\\spbu_master\\sem4\\vkr\\.venv\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4/5 | 139.70 min\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oobur\\Projects\\spbu_master\\sem4\\vkr\\.venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.52208 | val_0_auc: 0.91422 | val_0_accuracy: 0.84087 | val_0_amex_tabnet: 0.60947 |  0:00:58s\n",
      "epoch 1  | loss: 0.35341 | val_0_auc: 0.93089 | val_0_accuracy: 0.86691 | val_0_amex_tabnet: 0.67317 |  0:01:58s\n",
      "epoch 2  | loss: 0.31382 | val_0_auc: 0.93686 | val_0_accuracy: 0.87103 | val_0_amex_tabnet: 0.6936  |  0:02:57s\n",
      "epoch 3  | loss: 0.29245 | val_0_auc: 0.93939 | val_0_accuracy: 0.87553 | val_0_amex_tabnet: 0.70164 |  0:03:57s\n",
      "epoch 4  | loss: 0.28356 | val_0_auc: 0.941   | val_0_accuracy: 0.87643 | val_0_amex_tabnet: 0.70746 |  0:04:57s\n",
      "epoch 5  | loss: 0.27425 | val_0_auc: 0.94713 | val_0_accuracy: 0.88363 | val_0_amex_tabnet: 0.73496 |  0:05:56s\n",
      "epoch 6  | loss: 0.25854 | val_0_auc: 0.95021 | val_0_accuracy: 0.88827 | val_0_amex_tabnet: 0.74826 |  0:06:57s\n",
      "epoch 7  | loss: 0.25163 | val_0_auc: 0.95257 | val_0_accuracy: 0.89185 | val_0_amex_tabnet: 0.75742 |  0:07:57s\n",
      "epoch 8  | loss: 0.24604 | val_0_auc: 0.95387 | val_0_accuracy: 0.89286 | val_0_amex_tabnet: 0.7628  |  0:08:58s\n",
      "epoch 9  | loss: 0.24343 | val_0_auc: 0.95428 | val_0_accuracy: 0.89395 | val_0_amex_tabnet: 0.76447 |  0:09:58s\n",
      "epoch 10 | loss: 0.24373 | val_0_auc: 0.95508 | val_0_accuracy: 0.89533 | val_0_amex_tabnet: 0.76643 |  0:10:59s\n",
      "epoch 11 | loss: 0.23908 | val_0_auc: 0.95698 | val_0_accuracy: 0.89838 | val_0_amex_tabnet: 0.77508 |  0:12:02s\n",
      "epoch 12 | loss: 0.23539 | val_0_auc: 0.95755 | val_0_accuracy: 0.89849 | val_0_amex_tabnet: 0.77772 |  0:13:05s\n",
      "epoch 13 | loss: 0.23189 | val_0_auc: 0.95879 | val_0_accuracy: 0.90035 | val_0_amex_tabnet: 0.7819  |  0:14:09s\n",
      "epoch 14 | loss: 0.22905 | val_0_auc: 0.95919 | val_0_accuracy: 0.90087 | val_0_amex_tabnet: 0.78296 |  0:15:14s\n",
      "epoch 15 | loss: 0.23345 | val_0_auc: 0.95821 | val_0_accuracy: 0.89961 | val_0_amex_tabnet: 0.78015 |  0:16:21s\n",
      "epoch 16 | loss: 0.23204 | val_0_auc: 0.95854 | val_0_accuracy: 0.90043 | val_0_amex_tabnet: 0.78344 |  0:17:43s\n",
      "epoch 17 | loss: 0.22972 | val_0_auc: 0.95893 | val_0_accuracy: 0.90012 | val_0_amex_tabnet: 0.78472 |  0:19:09s\n",
      "epoch 18 | loss: 0.22822 | val_0_auc: 0.95932 | val_0_accuracy: 0.8986  | val_0_amex_tabnet: 0.78574 |  0:20:39s\n",
      "epoch 19 | loss: 0.22626 | val_0_auc: 0.95974 | val_0_accuracy: 0.90134 | val_0_amex_tabnet: 0.78633 |  0:22:18s\n",
      "epoch 20 | loss: 0.23034 | val_0_auc: 0.95899 | val_0_accuracy: 0.90012 | val_0_amex_tabnet: 0.78505 |  0:24:00s\n",
      "epoch 21 | loss: 0.22968 | val_0_auc: 0.95928 | val_0_accuracy: 0.90073 | val_0_amex_tabnet: 0.78606 |  0:25:53s\n",
      "epoch 22 | loss: 0.22813 | val_0_auc: 0.95861 | val_0_accuracy: 0.89998 | val_0_amex_tabnet: 0.78203 |  0:28:05s\n",
      "epoch 23 | loss: 0.22659 | val_0_auc: 0.95981 | val_0_accuracy: 0.90176 | val_0_amex_tabnet: 0.78796 |  0:30:25s\n",
      "epoch 24 | loss: 0.22482 | val_0_auc: 0.95996 | val_0_accuracy: 0.90179 | val_0_amex_tabnet: 0.78707 |  0:32:55s\n",
      "epoch 25 | loss: 0.22854 | val_0_auc: 0.95928 | val_0_accuracy: 0.90017 | val_0_amex_tabnet: 0.78463 |  0:35:31s\n",
      "epoch 26 | loss: 0.22775 | val_0_auc: 0.95949 | val_0_accuracy: 0.90091 | val_0_amex_tabnet: 0.78593 |  0:38:25s\n",
      "epoch 27 | loss: 0.22661 | val_0_auc: 0.95997 | val_0_accuracy: 0.90192 | val_0_amex_tabnet: 0.78724 |  0:41:19s\n",
      "epoch 28 | loss: 0.22516 | val_0_auc: 0.95996 | val_0_accuracy: 0.90205 | val_0_amex_tabnet: 0.78664 |  0:44:20s\n",
      "epoch 29 | loss: 0.22312 | val_0_auc: 0.9602  | val_0_accuracy: 0.90226 | val_0_amex_tabnet: 0.78751 |  0:47:20s\n",
      "epoch 30 | loss: 0.22714 | val_0_auc: 0.95977 | val_0_accuracy: 0.902   | val_0_amex_tabnet: 0.78509 |  0:50:02s\n",
      "epoch 31 | loss: 0.22721 | val_0_auc: 0.95944 | val_0_accuracy: 0.90127 | val_0_amex_tabnet: 0.7827  |  0:52:41s\n",
      "epoch 32 | loss: 0.22543 | val_0_auc: 0.95965 | val_0_accuracy: 0.90029 | val_0_amex_tabnet: 0.78497 |  0:55:25s\n",
      "epoch 33 | loss: 0.22395 | val_0_auc: 0.96016 | val_0_accuracy: 0.90271 | val_0_amex_tabnet: 0.78763 |  0:58:22s\n",
      "epoch 34 | loss: 0.222   | val_0_auc: 0.9601  | val_0_accuracy: 0.90236 | val_0_amex_tabnet: 0.78751 |  1:01:18s\n",
      "epoch 35 | loss: 0.22667 | val_0_auc: 0.95887 | val_0_accuracy: 0.89931 | val_0_amex_tabnet: 0.78211 |  1:03:46s\n",
      "epoch 36 | loss: 0.22585 | val_0_auc: 0.95987 | val_0_accuracy: 0.90182 | val_0_amex_tabnet: 0.78714 |  1:06:22s\n",
      "epoch 37 | loss: 0.22496 | val_0_auc: 0.95977 | val_0_accuracy: 0.90143 | val_0_amex_tabnet: 0.78615 |  1:09:02s\n",
      "epoch 38 | loss: 0.22344 | val_0_auc: 0.95995 | val_0_accuracy: 0.90231 | val_0_amex_tabnet: 0.78707 |  1:11:55s\n",
      "epoch 39 | loss: 0.22143 | val_0_auc: 0.9601  | val_0_accuracy: 0.90278 | val_0_amex_tabnet: 0.78701 |  1:14:51s\n",
      "epoch 40 | loss: 0.22612 | val_0_auc: 0.9596  | val_0_accuracy: 0.90149 | val_0_amex_tabnet: 0.78499 |  1:16:43s\n",
      "epoch 41 | loss: 0.22555 | val_0_auc: 0.95959 | val_0_accuracy: 0.90192 | val_0_amex_tabnet: 0.78397 |  1:18:39s\n",
      "epoch 42 | loss: 0.22456 | val_0_auc: 0.95983 | val_0_accuracy: 0.90192 | val_0_amex_tabnet: 0.78528 |  1:21:02s\n",
      "epoch 43 | loss: 0.22304 | val_0_auc: 0.95985 | val_0_accuracy: 0.9018  | val_0_amex_tabnet: 0.78621 |  1:23:47s\n",
      "epoch 44 | loss: 0.22121 | val_0_auc: 0.96007 | val_0_accuracy: 0.90265 | val_0_amex_tabnet: 0.7867  |  1:26:39s\n",
      "epoch 45 | loss: 0.22593 | val_0_auc: 0.95974 | val_0_accuracy: 0.90145 | val_0_amex_tabnet: 0.7858  |  1:28:18s\n",
      "epoch 46 | loss: 0.2251  | val_0_auc: 0.95948 | val_0_accuracy: 0.902   | val_0_amex_tabnet: 0.78717 |  1:30:08s\n",
      "epoch 47 | loss: 0.22439 | val_0_auc: 0.95983 | val_0_accuracy: 0.90198 | val_0_amex_tabnet: 0.78646 |  1:32:32s\n",
      "epoch 48 | loss: 0.22263 | val_0_auc: 0.95979 | val_0_accuracy: 0.90216 | val_0_amex_tabnet: 0.784   |  1:35:12s\n",
      "epoch 49 | loss: 0.22083 | val_0_auc: 0.96009 | val_0_accuracy: 0.90218 | val_0_amex_tabnet: 0.78699 |  1:38:04s\n",
      "epoch 50 | loss: 0.22588 | val_0_auc: 0.95907 | val_0_accuracy: 0.8998  | val_0_amex_tabnet: 0.78522 |  1:39:49s\n",
      "epoch 51 | loss: 0.22495 | val_0_auc: 0.95936 | val_0_accuracy: 0.89925 | val_0_amex_tabnet: 0.78726 |  1:41:55s\n",
      "epoch 52 | loss: 0.2242  | val_0_auc: 0.95988 | val_0_accuracy: 0.90243 | val_0_amex_tabnet: 0.78628 |  1:44:32s\n",
      "epoch 53 | loss: 0.22277 | val_0_auc: 0.96011 | val_0_accuracy: 0.902   | val_0_amex_tabnet: 0.78736 |  1:47:19s\n",
      "epoch 54 | loss: 0.22086 | val_0_auc: 0.96036 | val_0_accuracy: 0.90299 | val_0_amex_tabnet: 0.78783 |  1:50:10s\n",
      "epoch 55 | loss: 0.22568 | val_0_auc: 0.95993 | val_0_accuracy: 0.90168 | val_0_amex_tabnet: 0.7879  |  1:51:53s\n",
      "epoch 56 | loss: 0.22493 | val_0_auc: 0.95983 | val_0_accuracy: 0.90166 | val_0_amex_tabnet: 0.78524 |  1:53:51s\n",
      "epoch 57 | loss: 0.22458 | val_0_auc: 0.95969 | val_0_accuracy: 0.90212 | val_0_amex_tabnet: 0.78548 |  1:56:28s\n",
      "epoch 58 | loss: 0.22246 | val_0_auc: 0.95979 | val_0_accuracy: 0.90201 | val_0_amex_tabnet: 0.78579 |  1:59:15s\n",
      "epoch 59 | loss: 0.22066 | val_0_auc: 0.96021 | val_0_accuracy: 0.90297 | val_0_amex_tabnet: 0.78764 |  2:02:03s\n",
      "Stop training because you reached max_epochs = 60 with best_epoch = 23 and best_val_0_amex_tabnet = 0.78796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oobur\\Projects\\spbu_master\\sem4\\vkr\\.venv\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 5/5 | 136.30 min\n",
      "OOF score across folds: 0.7885104454659271\n"
     ]
    }
   ],
   "source": [
    "# X_train = train.loc[train_idx]\n",
    "# y_train = target.loc[train_idx]\n",
    "\n",
    "# Create out of folds array\n",
    "oof_predictions = np.zeros((df_train.shape[0]))\n",
    "test_predictions = np.zeros(df_test.shape[0])\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances[\"feature\"] = df_train[num_features].columns.tolist()\n",
    "stats = pd.DataFrame()\n",
    "explain_matrices = []\n",
    "masks_ =[]\n",
    "\n",
    "target_col = 'target'\n",
    "group_col = 'customer_ID'\n",
    "\n",
    "target, groups = df_train[target_col].values, df_train[group_col].values\n",
    "    \n",
    "# kfold = StratifiedKFold(n_splits = CFG.N_folds, shuffle=True, random_state = CFG.seed)\n",
    "sgkf = StratifiedGroupKFold(CFG.N_folds, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "# for tr_idx, va_idx in sgkf.split(df_train[[group_col, target_col]], y, groups):\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(\n",
    "                sgkf.split(df_train[[group_col, target_col]], target, groups)):\n",
    "    print(f\"Fold {fold}\")\n",
    "\n",
    "    ## DEBUG MODE\n",
    "    if CFG.DEBUG == True:\n",
    "        if fold > 0:\n",
    "            print('\\nDEBUG mode activated: Will train only one fold...\\n')\n",
    "            break      \n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    X_tr, X_va = df_train.iloc[tr_idx][num_features], df_train.iloc[va_idx][num_features]\n",
    "    y_tr, y_va = target[tr_idx], target[va_idx]    \n",
    "\n",
    "    # X_train, y_train = train.loc[train_idx], target.loc[train_idx]\n",
    "    # X_valid, y_valid = train.loc[valid_idx], target.loc[valid_idx]        \n",
    "        \n",
    "    model = TabNetClassifier(n_d = 32,\n",
    "                             n_a = 32,\n",
    "                             n_steps = 3,\n",
    "                             gamma = 1.3,\n",
    "                             n_independent = 2,\n",
    "                             n_shared = 2,\n",
    "                             momentum = 0.02,\n",
    "                             clip_value = None,\n",
    "                             lambda_sparse = 1e-3,\n",
    "                             optimizer_fn = torch.optim.Adam,\n",
    "                             optimizer_params = dict(lr = 1e-3, weight_decay=1e-3),\n",
    "                             scheduler_fn = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n",
    "                             scheduler_params = {'T_0':5,\n",
    "                                                 'eta_min':1e-4,\n",
    "                                                 'T_mult':1,\n",
    "                                                 'last_epoch':-1},\n",
    "                             mask_type = 'entmax',\n",
    "                             seed = CFG.seed)\n",
    "    \n",
    "    ## train\n",
    "    model.fit(np.array(X_tr),\n",
    "              #np.array(y_tr.values.ravel()),\n",
    "              y_tr,\n",
    "              eval_set = [(np.array(X_va), y_va)],\n",
    "              max_epochs = CFG.max_epochs, # CFG.max_epochs\n",
    "              patience = 50,\n",
    "              batch_size = CFG.batch_size,\n",
    "              eval_metric = ['auc', 'accuracy', Amex_tabnet]) # Last metric is used for early stopping\n",
    "    \n",
    "    # Saving best model\n",
    "    # saving_path_name = f\"./fold{fold}\"\n",
    "    # saved_filepath = model.save_model(saving_path_name)\n",
    "    \n",
    "    # model explanability\n",
    "    explain_matrix, masks = model.explain(X_va.values)\n",
    "    explain_matrices.append(explain_matrix)\n",
    "    masks_.append(masks[0])\n",
    "    masks_.append(masks[1])\n",
    "    \n",
    "    # Inference\n",
    "    oof_predictions[va_idx] = model.predict_proba(X_va.values)[:, 1]\n",
    "\n",
    "    test_predictions += model.predict_proba(df_test[num_features].values)[:, 1]/5\n",
    "    feature_importances[f\"importance_fold{fold}+1\"] = model.feature_importances_\n",
    "    \n",
    "    # Loss , metric tracking\n",
    "    stats[f'fold{fold+1}_train_loss'] = model.history['loss']\n",
    "    stats[f'fold{fold+1}_val_metric'] = model.history['val_0_amex_tabnet']\n",
    "\n",
    "    end = time.time()\n",
    "    time_delta = np.round((end - start)/60, 2)\n",
    "     \n",
    "    print(f'\\nFold {fold+1}/{CFG.N_folds} | {time_delta:.2f} min')\n",
    "\n",
    "    ### free memory\n",
    "    del X_tr, y_tr\n",
    "    del X_va, y_va\n",
    "    gc.collect()\n",
    "\n",
    "print(f'OOF score across folds: {get_amex_metric_calculated(target, oof_predictions.flatten())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c8fec5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12710182, 0.01828349, 0.03937742, ..., 0.51745488, 0.32151679,\n",
       "       0.03944453], shape=(924621,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4f09227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0378257 , 0.00226313, 0.04991527, ..., 0.58437125, 0.23511358,\n",
       "       0.08121067], shape=(924621,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f64163ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.24355196589327263)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "807a891a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924621,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2485213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>0.037826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...</td>\n",
       "      <td>0.002263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...</td>\n",
       "      <td>0.049915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...</td>\n",
       "      <td>0.307008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...</td>\n",
       "      <td>0.865024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924616</th>\n",
       "      <td>ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c...</td>\n",
       "      <td>0.013722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924617</th>\n",
       "      <td>ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3...</td>\n",
       "      <td>0.789601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924618</th>\n",
       "      <td>ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475...</td>\n",
       "      <td>0.584371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924619</th>\n",
       "      <td>ffffddef1fc3643ea179c93245b68dca0f36941cd83977...</td>\n",
       "      <td>0.235114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924620</th>\n",
       "      <td>fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61...</td>\n",
       "      <td>0.081211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924621 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_ID  prediction\n",
       "0       00000469ba478561f23a92a868bd366de6f6527a684c9a...    0.037826\n",
       "1       00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...    0.002263\n",
       "2       0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...    0.049915\n",
       "3       00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...    0.307008\n",
       "4       00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...    0.865024\n",
       "...                                                   ...         ...\n",
       "924616  ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c...    0.013722\n",
       "924617  ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3...    0.789601\n",
       "924618  ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475...    0.584371\n",
       "924619  ffffddef1fc3643ea179c93245b68dca0f36941cd83977...    0.235114\n",
       "924620  fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61...    0.081211\n",
       "\n",
       "[924621 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INFERENCE = True\n",
    "\n",
    "if INFERENCE:\n",
    "    sub = pd.DataFrame({'customer_ID': df_test.customer_ID,\n",
    "                        'prediction': test_predictions})\n",
    "    sub.to_csv('submission_tabnet_all_features.csv', index=False)\n",
    "    display(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6b3528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee9898f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54d63e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
