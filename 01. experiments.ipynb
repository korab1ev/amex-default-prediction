{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2300091",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run import_libs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efae5a30",
   "metadata": {},
   "source": [
    "### get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c50fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 151)\n",
      "(458913, 151)\n",
      "(458913, 151)\n",
      "(458913, 162)\n",
      "(458913, 616)\n"
     ]
    }
   ],
   "source": [
    "df_train = get_train_data(TRAIN_PATH='./data/train.parquet')\n",
    "num_features = pd.read_csv(\"num_feats_after_filtering.csv\")[\"0\"].to_list()\n",
    "\n",
    "df_train_agg = get_df_w_aggrs(df=df_train, feats=num_features)\n",
    "df_train_target = get_target(TARGET_PATH='./data/train_labels.csv')\n",
    "df_train = get_train_data_with_target_merged(df_train=df_train_agg, df_train_target=df_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc3fc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_min</th>\n",
       "      <th>P_3_min</th>\n",
       "      <th>P_4_min</th>\n",
       "      <th>D_39_min</th>\n",
       "      <th>D_41_min</th>\n",
       "      <th>D_42_min</th>\n",
       "      <th>D_43_min</th>\n",
       "      <th>D_44_min</th>\n",
       "      <th>D_45_min</th>\n",
       "      <th>...</th>\n",
       "      <th>D_114_last</th>\n",
       "      <th>D_116_last</th>\n",
       "      <th>D_117_last</th>\n",
       "      <th>D_120_last</th>\n",
       "      <th>D_126_last</th>\n",
       "      <th>D_63_last</th>\n",
       "      <th>D_64_last</th>\n",
       "      <th>D_66_last</th>\n",
       "      <th>D_68_last</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0.868580</td>\n",
       "      <td>0.581678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.708906</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>0.861109</td>\n",
       "      <td>0.510142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060646</td>\n",
       "      <td>0</td>\n",
       "      <td>0.239459</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>0.797670</td>\n",
       "      <td>0.381123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222406</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 617 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID   P_2_min   P_3_min  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.868580  0.581678   \n",
       "1  00000fd6641609c6ece5454664794f0340ad84dddce9a2...  0.861109  0.510142   \n",
       "2  00001b22f846c82c51f6e3958ccd81970162bae8b007e8...  0.797670  0.381123   \n",
       "\n",
       "   P_4_min  D_39_min  D_41_min  D_42_min  D_43_min  D_44_min  D_45_min  ...  \\\n",
       "0      0.0         0       0.0       NaN       NaN         0  0.708906  ...   \n",
       "1      0.0         0       0.0       NaN  0.060646         0  0.239459  ...   \n",
       "2      0.0         0       0.0       NaN       NaN         0  0.222406  ...   \n",
       "\n",
       "   D_114_last  D_116_last  D_117_last  D_120_last  D_126_last  D_63_last  \\\n",
       "0           1           0           5           0           2          0   \n",
       "1           1           0           0           0           2          3   \n",
       "2           1           0           0           0           2          3   \n",
       "\n",
       "   D_64_last  D_66_last  D_68_last  target  \n",
       "0          0         -1          6       0  \n",
       "1          0         -1          6       0  \n",
       "2          2         -1          6       0  \n",
       "\n",
       "[3 rows x 617 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcdd2bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B_30_last',\n",
       " 'B_38_last',\n",
       " 'D_114_last',\n",
       " 'D_116_last',\n",
       " 'D_117_last',\n",
       " 'D_120_last',\n",
       " 'D_126_last',\n",
       " 'D_63_last',\n",
       " 'D_64_last',\n",
       " 'D_66_last',\n",
       " 'D_68_last']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = [f\"{f}_last\" for f in ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']]\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93a232e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_feats = []\n",
    "delinq_feats = []\n",
    "spend_feats = []\n",
    "balance_feats = []\n",
    "risk_feats = []\n",
    "\n",
    "for feat in list(df_train):\n",
    "    if feat in cat_features:\n",
    "        continue\n",
    "    \n",
    "    if feat[0] == 'P':\n",
    "        #print(feat)\n",
    "        payment_feats.append(feat)\n",
    "    elif feat[0] == 'D':\n",
    "        delinq_feats.append(feat)\n",
    "    elif feat[0] == 'S':\n",
    "        spend_feats.append(feat)\n",
    "    elif feat[0] == 'B':\n",
    "        balance_feats.append(feat)\n",
    "    elif feat[0] == 'R':\n",
    "        risk_feats.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2bd2588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(payment_feats) + len(delinq_feats) + len(spend_feats) + len(balance_feats) + len(risk_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90c77e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = payment_feats + delinq_feats + spend_feats + balance_feats + risk_feats\n",
    "len(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326907c9",
   "metadata": {},
   "source": [
    "### Backward feature selection (lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fb8276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ metric --------------------------------------------------\n",
    "def get_amex_metric_calculated(y_true, y_pred):\n",
    "    n_pos = y_true.sum(); n_neg = y_true.size - n_pos\n",
    "    idx = np.argsort(y_pred)[::-1]; target = y_true[idx]\n",
    "    weight = 20 - 19 * target; cum_w = (weight / weight.sum()).cumsum()\n",
    "    d = target[cum_w <= .04].sum() / n_pos\n",
    "    lor = (target / n_pos).cumsum(); g = ((lor - cum_w) * weight).sum()\n",
    "    g_max = 10 * n_neg * (1 - 19 / (n_pos + 20 * n_neg))\n",
    "    return .5 * (g / g_max + d)\n",
    "\n",
    "def lgb_amex_metric(y_true, y_pred): return ('amex', get_amex_metric_calculated(y_true, y_pred), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e733d636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ backward + tuning --------------------------------------\n",
    "def backward_optuna_lgb(df, y_col, num_feats, cat_feats, group_col,\n",
    "                        min_feats=20, random_state=42, trials_per_tune=30):\n",
    "\n",
    "    num, cat = num_feats.copy(), cat_feats.copy()\n",
    "    hist, step = [], 0\n",
    "    sgkf = StratifiedGroupKFold(5, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # --- default hp (will evolve) ---\n",
    "    best_params = dict(\n",
    "        learning_rate   = 0.05,\n",
    "        subsample       = 0.9,\n",
    "        subsample_freq  = 1,      # make subsample actually active\n",
    "        colsample_bytree= 0.8,\n",
    "        objective       = 'binary',\n",
    "        random_state    = random_state,\n",
    "        max_depth       = 5,\n",
    "        num_leaves      = 64,\n",
    "        n_estimators    = 350,\n",
    "        verbosity=-1,\n",
    "    )\n",
    "\n",
    "    def cv_score(features, params):\n",
    "        scores = []\n",
    "        for tr, va in sgkf.split(df[[group_col, y_col]], df[y_col], df[group_col]):\n",
    "            Xtr, Xva = df.loc[tr, features], df.loc[va, features]\n",
    "            ytr, yva = df[y_col].iloc[tr].values, df[y_col].iloc[va].values\n",
    "            mdl = LGBMClassifier(**params); \n",
    "            mdl.fit(Xtr, ytr, categorical_feature=[f for f in cat if f in features], verbose=False)\n",
    "            scores.append(get_amex_metric_calculated(yva, mdl.predict_proba(Xva)[:,1]))\n",
    "        return float(np.mean(scores))\n",
    "\n",
    "    def decide_drop(n):\n",
    "        if n > 250: return max(1, int(n*.10))\n",
    "        if n > 100: return max(1, int(n*.05))\n",
    "        if n > 30 : return max(1, int(n*.02))\n",
    "        return 1\n",
    "\n",
    "    while True:\n",
    "        feats = num + cat\n",
    "        if len(feats) <= min_feats: break\n",
    "        step += 1\n",
    "\n",
    "        # ---- optuna tuning occasionally -------------------------------\n",
    "        if step % 5 == 1:                    # 1,6,11,...\n",
    "            def objective(trial):\n",
    "                params = best_params | {\n",
    "                    'max_depth'  : trial.suggest_int('max_depth', 3, 8),\n",
    "                    'num_leaves' : trial.suggest_int('num_leaves', 2**4, 2**8),\n",
    "                    'n_estimators': trial.suggest_int('n_estimators', 200, 500)\n",
    "                }\n",
    "                return -cv_score(feats, params)   # Optuna minimises\n",
    "            study = optuna.create_study(direction='minimize',\n",
    "                                         sampler=optuna.samplers.TPESampler(seed=random_state),\n",
    "                                         pruner=optuna.pruners.MedianPruner())\n",
    "            study.optimize(objective, n_trials=trials_per_tune, show_progress_bar=False)\n",
    "            best_params |= {k:v for k,v in study.best_params.items()}\n",
    "\n",
    "        # ---- CV with current params -----------------------------------\n",
    "        mean_cv = cv_score(feats, best_params)\n",
    "        ci_lo, ci_hi = stats.t.interval(0.95, 4, loc=mean_cv, scale=0 if np.isnan(mean_cv) else stats.sem([mean_cv]*5))\n",
    "\n",
    "        # ---- gain importance on full data -----------------------------\n",
    "        model_full = LGBMClassifier(**best_params)\n",
    "        model_full.fit(df[feats], df[y_col], categorical_feature=cat, verbose=False)\n",
    "        gain = model_full.booster_.feature_importance('gain')\n",
    "        imp_df = pd.DataFrame({'feature':feats,'gain':gain}).query('gain>0').sort_values('gain')\n",
    "\n",
    "        n_drop = min(decide_drop(len(feats)), len(imp_df))\n",
    "        drop_list = imp_df.head(n_drop)['feature'].tolist()\n",
    "        num = [f for f in num if f not in drop_list]\n",
    "        cat = [f for f in cat if f not in drop_list]\n",
    "\n",
    "        hist.append({\n",
    "            'step': step,\n",
    "            'n_feats_left': len(feats),\n",
    "            'n_num_left': len(num),\n",
    "            'n_cat_left': len(cat),\n",
    "            'cv_mean': mean_cv,\n",
    "            'cv_ci_lo': ci_lo,\n",
    "            'cv_ci_hi': ci_hi,\n",
    "            'dropped': drop_list,\n",
    "            'params': best_params.copy()\n",
    "        })\n",
    "\n",
    "    log_df = pd.DataFrame(hist)\n",
    "    final_feats = num + cat\n",
    "    final_model = LGBMClassifier(**best_params).fit(df[final_feats], df[y_col],\n",
    "                                                       categorical_feature=cat, verbose=False)\n",
    "    return log_df, {'num': num, 'cat': cat}, final_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2918ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(604, 11)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_features), len(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3d20326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 13:42:21,090] A new study created in memory with name: no-name-fd9ad5d3-e5e5-44ee-8858-7fc79da99e53\n",
      "[W 2025-05-04 13:43:22,613] Trial 0 failed with parameters: {'max_depth': 5, 'num_leaves': 245, 'n_estimators': 420} because of the following error: TypeError(\"LGBMClassifier.fit() got an unexpected keyword argument 'verbose'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\oobur\\Projects\\spbu_master\\sem4\\vkr\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\oobur\\AppData\\Local\\Temp\\ipykernel_8292\\2593188712.py\", line 51, in objective\n",
      "    return -cv_score(feats, params)   # Optuna minimises\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\oobur\\AppData\\Local\\Temp\\ipykernel_8292\\2593188712.py\", line 28, in cv_score\n",
      "    mdl.fit(Xtr, ytr, categorical_feature=[f for f in cat if f in features], verbose=False)\n",
      "TypeError: LGBMClassifier.fit() got an unexpected keyword argument 'verbose'\n",
      "[W 2025-05-04 13:43:22,613] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LGBMClassifier.fit() got an unexpected keyword argument 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m log, remaining, model = \u001b[43mbackward_optuna_lgb\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtarget\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_feats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcat_feats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcustomer_ID\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrials_per_tune\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# raise if you want deeper search\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(log[[\u001b[33m'\u001b[39m\u001b[33mstep\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mn_feats_left\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mcv_mean\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mdropped\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m'\u001b[39m]].head())\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLeft:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(remaining[\u001b[33m'\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m'\u001b[39m]), \u001b[33m\"\u001b[39m\u001b[33mnum &\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(remaining[\u001b[33m'\u001b[39m\u001b[33mcat\u001b[39m\u001b[33m'\u001b[39m]), \u001b[33m\"\u001b[39m\u001b[33mcat\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mbackward_optuna_lgb\u001b[39m\u001b[34m(df, y_col, num_feats, cat_feats, group_col, min_feats, random_state, trials_per_tune)\u001b[39m\n\u001b[32m     51\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m -cv_score(feats, params)   \u001b[38;5;66;03m# Optuna minimises\u001b[39;00m\n\u001b[32m     52\u001b[39m     study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     53\u001b[39m                                  sampler=optuna.samplers.TPESampler(seed=random_state),\n\u001b[32m     54\u001b[39m                                  pruner=optuna.pruners.MedianPruner())\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrials_per_tune\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     best_params |= {k:v \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m study.best_params.items()}\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# ---- CV with current params -----------------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oobur\\Projects\\spbu_master\\sem4\\vkr\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oobur\\Projects\\spbu_master\\sem4\\vkr\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oobur\\Projects\\spbu_master\\sem4\\vkr\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oobur\\Projects\\spbu_master\\sem4\\vkr\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oobur\\Projects\\spbu_master\\sem4\\vkr\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mbackward_optuna_lgb.<locals>.objective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjective\u001b[39m(trial):\n\u001b[32m     46\u001b[39m     params = best_params | {\n\u001b[32m     47\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m  : trial.suggest_int(\u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m8\u001b[39m),\n\u001b[32m     48\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mnum_leaves\u001b[39m\u001b[33m'\u001b[39m : trial.suggest_int(\u001b[33m'\u001b[39m\u001b[33mnum_leaves\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m2\u001b[39m**\u001b[32m4\u001b[39m, \u001b[32m2\u001b[39m**\u001b[32m8\u001b[39m),\n\u001b[32m     49\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_int(\u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m200\u001b[39m, \u001b[32m500\u001b[39m)\n\u001b[32m     50\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -\u001b[43mcv_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mbackward_optuna_lgb.<locals>.cv_score\u001b[39m\u001b[34m(features, params)\u001b[39m\n\u001b[32m     26\u001b[39m     ytr, yva = df[y_col].iloc[tr].values, df[y_col].iloc[va].values\n\u001b[32m     27\u001b[39m     mdl = LGBMClassifier(**params); \n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     \u001b[43mmdl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     scores.append(get_amex_metric_calculated(yva, mdl.predict_proba(Xva)[:,\u001b[32m1\u001b[39m]))\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np.mean(scores))\n",
      "\u001b[31mTypeError\u001b[39m: LGBMClassifier.fit() got an unexpected keyword argument 'verbose'"
     ]
    }
   ],
   "source": [
    "log, remaining, model = backward_optuna_lgb(\n",
    "        df=df_train,\n",
    "        y_col='target',\n",
    "        num_feats=num_features,\n",
    "        cat_feats=cat_features,\n",
    "        group_col='customer_ID',\n",
    "        trials_per_tune=40)   # raise if you want deeper search\n",
    "\n",
    "print(log[['step','n_feats_left','cv_mean','dropped','params']].head())\n",
    "print(\"Left:\", len(remaining['num']), \"num &\", len(remaining['cat']), \"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fce95d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f5f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719463c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
