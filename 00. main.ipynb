{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from typing import List\n",
    "\n",
    "# models\n",
    "from lightgbm import LGBMClassifier, log_evaluation\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action = \"ignore\", category = RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_amex_metric_calculated(y_true: np.array, y_pred: np.array) -> float:\n",
    "    # count of positives and negatives\n",
    "    n_pos = y_true.sum()\n",
    "    n_neg = y_true.shape[0] - n_pos\n",
    "\n",
    "    # sorting by descring prediction values\n",
    "    indices = np.argsort(y_pred)[::-1]\n",
    "    preds, target = y_pred[indices], y_true[indices]\n",
    "\n",
    "    # filter the top 4% by cumulative row weights\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_filter = cum_norm_weight <= 0.04\n",
    "\n",
    "    # default rate captured at 4%\n",
    "    d = target[four_pct_filter].sum() / n_pos\n",
    "\n",
    "    # weighted gini coefficient\n",
    "    lorentz = (target / n_pos).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    # max weighted gini coefficient\n",
    "    gini_max = 10 * n_neg * (1 - 19 / (n_pos + 20 * n_neg))\n",
    "\n",
    "    # normalized weighted gini coefficient\n",
    "    g = gini / gini_max\n",
    "\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "\n",
    "def lgb_amex_metric(y_true, y_pred):\n",
    "    \"\"\"The competition metric with lightgbm's calling convention\"\"\"\n",
    "    return ('amex', get_amex_metric_calculated(y_true, y_pred), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(TRAIN_PATH: str) -> pd.DataFrame:\n",
    "    '''Returns train dataset'''\n",
    "    df_train = pd.read_parquet(TRAIN_PATH)\n",
    "    return df_train\n",
    "\n",
    "\n",
    "def get_test_data(TEST_PATH: str) -> pd.DataFrame:\n",
    "    '''Returns test dataset'''\n",
    "    df_test = pd.read_parquet(TEST_PATH)\n",
    "    return df_test\n",
    "\n",
    "\n",
    "def get_target(TARGET_PATH: str) -> pd.DataFrame:\n",
    "    '''Retruns dataset with train targets'''\n",
    "    df_train_target = pd.read_csv(TARGET_PATH)\n",
    "    return df_train_target\n",
    "\n",
    "\n",
    "def get_train_data_with_target_merged(df_train: pd.DataFrame, df_train_target: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''Retruns train dataset with target variable merged'''\n",
    "    df_train_w_target = (\n",
    "        df_train\n",
    "        .merge(df_train_target,\n",
    "            on='customer_ID',\n",
    "            how='left'\n",
    "        )\n",
    "    )\n",
    "    # df_train_w_target.groupby('target', dropna=False).count()['customer_ID']\n",
    "    '''\n",
    "    target\n",
    "    0    4153582\n",
    "    1    1377869\n",
    "    Name: customer_ID, dtype: int64    \n",
    "    '''\n",
    "    return df_train_w_target\n",
    "\n",
    "\n",
    "def get_all_features(df: pd.DataFrame) -> List:\n",
    "    '''Returns list of all features from the dataset'''\n",
    "    return list(df)\n",
    "\n",
    "\n",
    "def get_cat_features() -> List:\n",
    "    '''Returns list of categorical features from the dataset'''\n",
    "    cat_features = ['B_30', 'B_38', 'D_114', \n",
    "                    'D_116', 'D_117', 'D_120', \n",
    "                    'D_126', 'D_63', 'D_64', \n",
    "                    'D_66', 'D_68']\n",
    "    \n",
    "    return cat_features\n",
    "\n",
    "\n",
    "def get_num_features(all_features: List, cat_features: List) -> List:\n",
    "    '''Returns list of all numerical features from the dataset'''\n",
    "    num_feats = [col for col in all_features if col not in cat_features + ['customer_ID', 'S_2', 'target']]\n",
    "\n",
    "    return num_feats\n",
    "\n",
    "\n",
    "def get_df_w_aggrs(df: pd.DataFrame, feats: List) ->  pd.DataFrame:\n",
    "    '''Returns dataframe with generated aggregates based on numerical features'''\n",
    "\n",
    "    cid = pd.Categorical(df.pop('customer_ID'), ordered=True)\n",
    "    last = (cid != np.roll(cid, -1)) # mask for last statement of every customer\n",
    "\n",
    "    df_min = (df\n",
    "        .groupby(cid)\n",
    "        .min()[feats]\n",
    "        .rename(columns={f: f\"{f}_min\" for f in feats})\n",
    "    )\n",
    "    print(df_min.shape)\n",
    "\n",
    "    df_max = (df\n",
    "        .groupby(cid)\n",
    "        .max()[feats]\n",
    "        .rename(columns={f: f\"{f}_max\" for f in feats})\n",
    "    )\n",
    "    print(df_max.shape)\n",
    "\n",
    "    df_avg = (df\n",
    "        .drop('S_2', axis='columns')\n",
    "        .groupby(cid)\n",
    "        .mean()[feats]\n",
    "        .rename(columns={f: f\"{f}_avg\" for f in feats})\n",
    "    )\n",
    "    print(df_avg.shape)\n",
    "\n",
    "    df_last = (df\n",
    "        .loc[last, feats]\n",
    "        .rename(columns={f: f\"{f}_last\" for f in feats})\n",
    "        .set_index(np.asarray(cid[last]))\n",
    "    )\n",
    "    print(df_last.shape)\n",
    "\n",
    "    df_aggrs = (pd.concat([df_min, df_max, df_avg, df_last], axis=1)\n",
    "        .reset_index()\n",
    "        .rename(columns={'index': 'customer_ID'})\n",
    "    )\n",
    "    print(df_aggrs.shape)\n",
    "\n",
    "    '''\n",
    "    del df, df_min, df_max, df_avg, cid, last\n",
    "    gc.collect()\n",
    "    '''\n",
    "    return df_aggrs\n",
    "\n",
    "\n",
    "def check_zapolnenie(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''Returns pd.DataFrame with isNotNullShare of each column of given df'''\n",
    "    # Calculate percent of not null share each column \n",
    "    col_pct_notNull = [] \n",
    "    for col in df.columns: \n",
    "        percent_notNull = np.mean(~df[col].isnull())*100 \n",
    "        col_pct_notNull.append([col, percent_notNull]) \n",
    "        \n",
    "    col_pct_notNull_df = pd.DataFrame(col_pct_notNull, columns = ['column_name','isNotNullShare']).sort_values(by = 'isNotNullShare', ascending = False) \n",
    "    #print(col_pct_notNull_df)\n",
    "    return col_pct_notNull_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oobur\\AppData\\Local\\Temp\\ipykernel_14784\\2036179205.py:81: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  .groupby(cid)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 177)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oobur\\AppData\\Local\\Temp\\ipykernel_14784\\2036179205.py:88: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  .groupby(cid)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 177)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oobur\\AppData\\Local\\Temp\\ipykernel_14784\\2036179205.py:96: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  .groupby(cid)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 177)\n",
      "(458913, 177)\n",
      "(458913, 709)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndf_train.target.value_counts()\\ntarget\\n0    340085\\n1    118828\\nName: count, dtype: int64\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = get_train_data(TRAIN_PATH='./data/train.parquet')\n",
    "\n",
    "all_features = get_all_features(df_train)\n",
    "cat_features = get_cat_features()\n",
    "num_features = get_num_features(all_features, cat_features)\n",
    "# len(all_features), len(cat_features), len(num_features) -> (190, 11, 178)\n",
    "\n",
    "df_train_agg = get_df_w_aggrs(df=df_train, feats=num_features)\n",
    "df_train_target = get_target(TARGET_PATH='./data/train_labels.csv')\n",
    "df_train = get_train_data_with_target_merged(df_train=df_train_agg, df_train_target=df_train_target)\n",
    "\n",
    "'''\n",
    "df_train.target.value_counts()\n",
    "target\n",
    "0    340085\n",
    "1    118828\n",
    "Name: count, dtype: int64\n",
    "'''\n",
    "\n",
    "# df_test = get_test_data(TEST_PATH='./data/test.parquet')\n",
    "# df_test = get_df_w_aggrs(df=df_test, feats=num_features)\n",
    "\n",
    "# zapolnenie_train = check_zapolnenie(df_train)\n",
    "# zapolnenie_test = check_zapolnenie(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "clf.fit(\n",
    "    X: Union[lightgbm.compat.dt_DataTable, List[Union[List[float], List[int]]], numpy.ndarray, pandas.core.frame.DataFrame, scipy.sparse._matrix.spmatrix],\n",
    "    y: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Array, pyarrow.lib.ChunkedArray],\n",
    "    sample_weight: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None,\n",
    "    init_score: Union[List[float], List[List[float]], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Table, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None,\n",
    "    eval_set: Optional[List[Tuple[Union[lightgbm.compat.dt_DataTable, List[Union[List[float], List[int]]], numpy.ndarray, pandas.core.frame.DataFrame, scipy.sparse._matrix.spmatrix], Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Array, pyarrow.lib.ChunkedArray]]]] = None,\n",
    "    eval_names: Optional[List[str]] = None,\n",
    "    eval_sample_weight: Optional[List[Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray]]] = None,\n",
    "    eval_class_weight: Optional[List[float]] = None,\n",
    "    eval_init_score: Optional[List[Union[List[float], List[List[float]], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Table, pyarrow.lib.Array, pyarrow.lib.ChunkedArray]]] = None,\n",
    "    eval_metric: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], List[Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], List[Tuple[str, float, bool]]]]], NoneType] = None,\n",
    "    feature_name: Union[List[str], ForwardRef(\"Literal['auto']\")] = 'auto',\n",
    "    categorical_feature: Union[List[str], List[int], ForwardRef(\"Literal['auto']\")] = 'auto',\n",
    "    callbacks: Optional[List[Callable]] = None,\n",
    "    init_model: Union[str, pathlib.Path, lightgbm.basic.Booster, lightgbm.sklearn.LGBMModel, NoneType] = None,\n",
    ") -> 'LGBMClassifier'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выделение групп признаков (из исходных признаков)\n",
    "\n",
    "payment_feats = []\n",
    "delinq_feats = []\n",
    "spend_feats = []\n",
    "balance_feats = []\n",
    "risk_feats = []\n",
    "\n",
    "for feat in num_features:\n",
    "    if feat[0] == 'P':\n",
    "        #print(feat)\n",
    "        payment_feats.append(feat)\n",
    "    elif feat[0] == 'D':\n",
    "        delinq_feats.append(feat)\n",
    "    elif feat[0] == 'S':\n",
    "        spend_feats.append(feat)\n",
    "    elif feat[0] == 'B':\n",
    "        balance_feats.append(feat)\n",
    "    elif feat[0] == 'R':\n",
    "        risk_feats.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(payment_feats) + len(delinq_feats) + len(spend_feats) + len(balance_feats) + len(risk_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выделение групп признаков (из всех признаков, вариант после аггрегирования)\n",
    "\n",
    "payment_feats = []\n",
    "delinq_feats = []\n",
    "spend_feats = []\n",
    "balance_feats = []\n",
    "risk_feats = []\n",
    "\n",
    "for feat in list(df_train):\n",
    "    if feat[0] == 'P':\n",
    "        #print(feat)\n",
    "        payment_feats.append(feat)\n",
    "    elif feat[0] == 'D':\n",
    "        delinq_feats.append(feat)\n",
    "    elif feat[0] == 'S':\n",
    "        spend_feats.append(feat)\n",
    "    elif feat[0] == 'B':\n",
    "        balance_feats.append(feat)\n",
    "    elif feat[0] == 'R':\n",
    "        risk_feats.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "708"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(payment_feats) + len(delinq_feats) + len(spend_feats) + len(balance_feats) + len(risk_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgkf_gr = StratifiedGroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([     1,      2,      3, ..., 458909, 458910, 458912],\n",
       "       shape=(367130,)),\n",
       " array([     0,      5,     10, ..., 458902, 458907, 458911],\n",
       "       shape=(91783,)))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(sgkf_gr.split(X=df_train[['customer_ID', 'target']], y=df_train['target'], groups=df_train['customer_ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P_2_min', 'P_3_min']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(payment_feats + delinq_feats + spend_feats + balance_feats + risk_feats)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "P_2_min\n",
      "==================================================\n",
      "\n",
      "0\n",
      "[100]\tvalid_0's binary_logloss: 0.337375\tvalid_0's amex: 0.59905\n",
      "[200]\tvalid_0's binary_logloss: 0.337074\tvalid_0's amex: 0.599415\n",
      "Score = 0.59915\n",
      "1\n",
      "[100]\tvalid_0's binary_logloss: 0.336377\tvalid_0's amex: 0.599288\n",
      "[200]\tvalid_0's binary_logloss: 0.335946\tvalid_0's amex: 0.599219\n",
      "Score = 0.59896\n",
      "2\n",
      "[100]\tvalid_0's binary_logloss: 0.338069\tvalid_0's amex: 0.594974\n",
      "[200]\tvalid_0's binary_logloss: 0.337847\tvalid_0's amex: 0.594606\n",
      "Score = 0.59437\n",
      "3\n",
      "[100]\tvalid_0's binary_logloss: 0.336796\tvalid_0's amex: 0.601091\n",
      "[200]\tvalid_0's binary_logloss: 0.336457\tvalid_0's amex: 0.600334\n",
      "Score = 0.60010\n",
      "4\n",
      "[100]\tvalid_0's binary_logloss: 0.339635\tvalid_0's amex: 0.597166\n",
      "[200]\tvalid_0's binary_logloss: 0.339386\tvalid_0's amex: 0.597362\n",
      "Score = 0.59710\n",
      "==================================================\n",
      "P_3_min\n",
      "==================================================\n",
      "\n",
      "0\n",
      "[100]\tvalid_0's binary_logloss: 0.497178\tvalid_0's amex: 0.33916\n",
      "[200]\tvalid_0's binary_logloss: 0.497014\tvalid_0's amex: 0.338426\n",
      "Score = 0.33816\n",
      "1\n",
      "[100]\tvalid_0's binary_logloss: 0.494973\tvalid_0's amex: 0.346625\n",
      "[200]\tvalid_0's binary_logloss: 0.494851\tvalid_0's amex: 0.346297\n",
      "Score = 0.34603\n",
      "2\n",
      "[100]\tvalid_0's binary_logloss: 0.497608\tvalid_0's amex: 0.337203\n",
      "[200]\tvalid_0's binary_logloss: 0.497506\tvalid_0's amex: 0.336747\n",
      "Score = 0.33650\n",
      "3\n",
      "[100]\tvalid_0's binary_logloss: 0.495076\tvalid_0's amex: 0.34548\n",
      "[200]\tvalid_0's binary_logloss: 0.494925\tvalid_0's amex: 0.345678\n",
      "Score = 0.34543\n",
      "4\n",
      "[100]\tvalid_0's binary_logloss: 0.496776\tvalid_0's amex: 0.342379\n",
      "[200]\tvalid_0's binary_logloss: 0.496568\tvalid_0's amex: 0.342597\n",
      "Score = 0.34233\n"
     ]
    }
   ],
   "source": [
    "odnofactorniy_gini = []\n",
    "\n",
    "for feat in (payment_feats + delinq_feats + spend_feats + balance_feats + risk_feats)[:2]:\n",
    "    print(\"=\"*50)\n",
    "    print(feat)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    score_list = []\n",
    "\n",
    "    for fold, (idx_tr, idx_va) in enumerate(sgkf_gr.split(X=df_train[['customer_ID', 'target']], y=df_train['target'], groups=df_train['customer_ID'])):\n",
    "        print(fold)\n",
    "        X_tr, X_va, y_tr, y_va, clf = None, None, None, None, None\n",
    "\n",
    "\n",
    "        X_tr = df_train.iloc[idx_tr][[feat]] # 'P_2_min' -> feat\n",
    "        X_va = df_train.iloc[idx_va][[feat]] # 'P_2_min' -> feat\n",
    "        y_tr = df_train.target.values[idx_tr]\n",
    "        y_va = df_train.target.values[idx_va]\n",
    "\n",
    "\n",
    "        clf = LGBMClassifier(n_estimators=200,\n",
    "                     max_depth=2,\n",
    "                     learning_rate=0.05,\n",
    "                     colsample_bytree=0.8,\n",
    "                     subsample=0.95,\n",
    "                     subsample_freq=1,\n",
    "                     verbosity=-1,\n",
    "                     random_state=42)\n",
    "\n",
    "        # abc\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "            clf.fit(X_tr, \n",
    "                    y_tr,\n",
    "                    eval_set = [(X_va, y_va)],\n",
    "                    eval_metric=[lgb_amex_metric],\n",
    "                    callbacks=[log_evaluation(100)]\n",
    "                   )\n",
    "        # abc\n",
    "        X_tr, y_tr = None, None\n",
    "        y_va_pred = clf.predict_proba(X_va, raw_score=True)\n",
    "\n",
    "        '''\n",
    "        try:\n",
    "            print(len(y_va), len(y_va_pred))\n",
    "            print(type(y_va), type(y_va_pred))\n",
    "            print(y_va)\n",
    "            print()\n",
    "            print(y_va_pred)\n",
    "\n",
    "        except:\n",
    "            print(y_va.shape, y_va_pred.shape)\n",
    "        '''\n",
    "\n",
    "        score = get_amex_metric_calculated(y_va, y_va_pred)\n",
    "        print(f\"Score = {score:.5f}\")\n",
    "\n",
    "        score_list.append(score)\n",
    "        \n",
    "    odnofactorniy_gini.append(np.mean(score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сначала по каждой фиче первый фолд пробежать,\n",
    "# потом по каждой фиче второй фолд пробежать\n",
    "\n",
    "# это сильно ускорит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.33816325865187813),\n",
       " np.float64(0.34603465249740917),\n",
       " np.float64(0.3365027480013072),\n",
       " np.float64(0.34543407030664763),\n",
       " np.float64(0.34233374306508)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59794\n"
     ]
    }
   ],
   "source": [
    "print(f\"OOF Score: {np.mean(score_list):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.5979361673374026), np.float64(0.3416936945044644)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odnofactorniy_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P_2_min', 'P_3_min']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(payment_feats + delinq_feats + spend_feats + balance_feats + risk_feats)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>odnofactorniy_gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_2_min</th>\n",
       "      <td>0.597936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_3_min</th>\n",
       "      <td>0.341694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         odnofactorniy_gini\n",
       "P_2_min            0.597936\n",
       "P_3_min            0.341694"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(odnofactorniy_gini, (payment_feats + delinq_feats + spend_feats + balance_feats + risk_feats)[:2], columns=['odnofactorniy_gini'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>odnofactorniy_gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_2_min</th>\n",
       "      <td>0.597936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_3_min</th>\n",
       "      <td>0.341694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         odnofactorniy_gini\n",
       "P_2_min            0.597936\n",
       "P_3_min            0.341694"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(odnofactorniy_gini, (payment_feats + delinq_feats + spend_feats + balance_feats + risk_feats)[:2], columns=['odnofactorniy_gini']).sort_values(\"odnofactorniy_gini\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# однофакторный gini\n",
    "\n",
    "for feat in payment_feats + delinq_feats + spend_feats + balance_feats + risk_feats:\n",
    "    \n",
    "    \n",
    "    clf = LGBMClassifier(n_estimators=200,\n",
    "                     max_depth=2,\n",
    "                     learning_rate=0.05,\n",
    "                     colsample_bytree=0.8,\n",
    "                     subsample=0.95,\n",
    "                     subsample_freq=1,\n",
    "                     random_state=42)\n",
    "    \n",
    "    clf.fit(\n",
    "        X=df_train[[feat]],\n",
    "        y=df_train['target'],\n",
    "        cv=sgkf_gr\n",
    "    )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5)\n",
    "for fold, (idx_tr, idx_va) in enumerate(kf.split(train, target)):\n",
    "    X_tr, X_va, y_tr, y_va, model = None, None, None, None, None\n",
    "    start_time = datetime.datetime.now()\n",
    "    X_tr = train.iloc[idx_tr][features]\n",
    "    X_va = train.iloc[idx_va][features]\n",
    "    y_tr = target[idx_tr]\n",
    "    y_va = target[idx_va]\n",
    "    \n",
    "    model = my_booster()\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=UserWarning)\n",
    "        model.fit(X_tr, y_tr,\n",
    "                  eval_set = [(X_va, y_va)], \n",
    "                  eval_metric=[lgb_amex_metric],\n",
    "                  callbacks=[log_evaluation(100)])\n",
    "        \n",
    "    X_tr, y_tr = None, None\n",
    "    y_va_pred = model.predict_proba(X_va, raw_score=True)\n",
    "    score = amex_metric(y_va, y_va_pred)\n",
    "    n_trees = model.best_iteration_\n",
    "    if n_trees is None: n_trees = model.n_estimators\n",
    "    print(f\"{Fore.GREEN}{Style.BRIGHT}Fold {fold} | {str(datetime.datetime.now() - start_time)[-12:-7]} |\"\n",
    "          f\" {n_trees:5} trees |\"\n",
    "          f\"                Score = {score:.5f}{Style.RESET_ALL}\")\n",
    "    score_list.append(score)\n",
    "    \n",
    "    if INFERENCE:\n",
    "        y_pred_list.append(model.predict_proba(test[features], raw_score=True))\n",
    "        \n",
    "    if ONLY_FIRST_FOLD: break # we only want the first fold\n",
    "    \n",
    "print(f\"{Fore.GREEN}{Style.BRIGHT}OOF Score:                       {np.mean(score_list):.5f}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_amex_metric_calculated(y_true: np.array, y_pred: np.array) -> float:\n",
    "\n",
    "    # count of positives and negatives\n",
    "    n_pos = y_true.sum()\n",
    "    n_neg = y_true.shape[0] - n_pos\n",
    "\n",
    "    # sorting by descring prediction values\n",
    "    indices = np.argsort(y_pred)[::-1]\n",
    "    preds, target = y_pred[indices], y_true[indices]\n",
    "\n",
    "    # filter the top 4% by cumulative row weights\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_filter = cum_norm_weight <= 0.04\n",
    "\n",
    "    # default rate captured at 4%\n",
    "    d = target[four_pct_filter].sum() / n_pos\n",
    "\n",
    "    # weighted gini coefficient\n",
    "    lorentz = (target / n_pos).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    # max weighted gini coefficient\n",
    "    gini_max = 10 * n_neg * (1 - 19 / (n_pos + 20 * n_neg))\n",
    "\n",
    "    # normalized weighted gini coefficient\n",
    "    g = gini / gini_max\n",
    "\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000015785\n"
     ]
    }
   ],
   "source": [
    "print(get_amex_metric_calculated(y_true=df_train.target, y_pred=df_train.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_vkr_environment",
   "language": "python",
   "name": "my_vkr_environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
